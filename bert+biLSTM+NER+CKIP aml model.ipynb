{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cloud.tencent.com/developer/article/1454904\n",
    "#https://zhuanlan.zhihu.com/p/82850698\n",
    "#https://blog.csdn.net/weixin_42598761/article/details/104592171"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, Bidirectional, LSTM, Dense\n",
    "from keras_bert import load_trained_model_from_checkpoint\n",
    "from keras_contrib.layers import CRF\n",
    "from keras_contrib.losses import crf_loss\n",
    "from keras_contrib.metrics import crf_accuracy\n",
    "from keras_bert import Tokenizer\n",
    "from keras_bert import AdamWarmup, calc_train_steps\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "import keras.callbacks\n",
    "import re\n",
    "import codecs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ckiptagger import WS, POS, NER\n",
    "ckip_path = r'C:\\Users\\rocker\\Python - deep learning\\Deep learning\\keras 大神\\data'\n",
    "ws = WS(ckip_path, disable_cuda=False) #斷詞\n",
    "pos = POS(ckip_path, disable_cuda=False) #詞性標注\n",
    "ner = NER(ckip_path, disable_cuda=False) #實體辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bert_dir = r'C:\\Users\\rocker\\Python - deep learning\\Deep learning\\keras 大神\\bert'\n",
    "config_path = os.path.join(bert_dir, 'bert_config.json')\n",
    "checkpoint_path = os.path.join(bert_dir, 'bert_model.ckpt')\n",
    "dict_path = os.path.join(bert_dir, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 載入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\rocker\\Python - deep learning\\Deep learning\\keras 大神\\content_df_0620.csv')\n",
    "data = data[data[\"status\"]==\"ok\"].drop([\"url\",\"context\",\"raw_content\",\"status\", \"content_status\"],axis = 1)\n",
    "data['aml_label'] = data['name'].apply(lambda x: 0 if x == '[]' else 1)\n",
    "data['name'] = data['name'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(lambda x: re.sub('<[^>]*>|【[^】]*】|（[^）]*）|〔[^〕]*〕', '', x))\n",
    "data['content'] = data['content'].apply(lambda x: x.replace('記者', '＜')\n",
    "                                                   .replace('報導', '＞')\n",
    "                                                   .replace('▲', '')\\\n",
    "                                                   .replace('。　', '。')\\\n",
    "                                                   .replace('\b', '')\\\n",
    "                                                   .replace('.', '')\\\n",
    "                                                   .replace(' ', '')\\\n",
    "                                                   .replace('“', '「')\\\n",
    "                                                   .replace('”', '」'))\n",
    "data['content'] = data['content'].apply(lambda x: re.sub('＜[^＞]*＞', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(r'C:\\Users\\rocker\\extra data\\人肉爬蟲_20200615.csv', encoding='cp950')\n",
    "data2['name'] = data2['name'].apply(lambda x: eval(x))\n",
    "data2['content'] = data2['content'].apply(lambda x: re.sub('<[^>]*>|【[^】]*】|（[^）]*）|〔[^〕]*〕', '', x))\n",
    "data2['content'] = data2['content'].apply(lambda x: x.replace('記者', '＜')\n",
    "                                                   .replace('報導', '＞')\n",
    "                                                   .replace('▲', '')\\\n",
    "                                                   .replace('。　', '。')\\\n",
    "                                                   .replace('\b', '')\\\n",
    "                                                   .replace('.', '')\\\n",
    "                                                   .replace(' ', '')\\\n",
    "                                                   .replace('“', '「')\\\n",
    "                                                   .replace('”', '」'))\n",
    "data2['content'] = data2['content'].apply(lambda x: re.sub('＜[^＞]*＞', '', x))\n",
    "test = data2\n",
    "test = test[['news_id', 'name', 'content', 'aml_label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test =  train_test_split(data, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把大於512的train以逗點單雙句分開，預設為aml_label=1的都分，aml_label=0的中取frac比率分，藉此調整整體正反樣本比例\n",
    "def split_train(data,frac=1):\n",
    "    data_more_split = pd.DataFrame()\n",
    "    \n",
    "    data_0 = data[data['aml_label'] == 0].sample(frac=frac, replace=False)\n",
    "    data_1 = data[data['aml_label'] == 1]\n",
    "    data = data_0.append(data_1)\n",
    "    data_nochange_0 = data[~data['news_id'].isin(data_0['news_id'])]\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        if (len(row['content']) > 512) & (len(row['content']) <= 1024):\n",
    "\n",
    "            s = row['content'].split('，')\n",
    "            even = '，'.join([s for i, s in enumerate(s) if i % 2 == 0])\n",
    "            odd = '，'.join([s for i, s in enumerate(s) if i % 2 == 1])\n",
    "            contents = [even, odd]\n",
    "            \n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content, 'aml_label':row['aml_label']}, index=[66]), ignore_index=True)\n",
    "\n",
    "        elif len(row['content']) > 1024:\n",
    "\n",
    "            s = row['content'].split('，')\n",
    "            first = '，'.join([s for i, s in enumerate(s) if i % 3 == 0])\n",
    "            second = '，'.join([s for i, s in enumerate(s) if i % 3 == 1])\n",
    "            third = '，'.join([s for i, s in enumerate(s) if i % 3 == 2])\n",
    "            contents = [first, second, third]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content, 'aml_label':row['aml_label']}, index=[66]), ignore_index=True)\n",
    "    data_more_split = data_nochange_0.append(data_more_split)\n",
    "    return data_more_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分句\n",
    "train = train.drop(['name'], axis=1)\n",
    "data_less = train[train['content'].str.len() <= 512]\n",
    "data_more = train[train['content'].str.len() > 512]\n",
    "data_more_split = split_train(data_more, 1)\n",
    "train = train.append(data_more_split)\n",
    "train = train.reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = '曾找英國天后JessieJ、謝金燕、張惠妹等大牌藝人造勢的「富南斯」集團'\n",
    "input_id, segment_id = tokenizer.encode(content, max_len=maxlen)\n",
    "mask_input = [transfer(i) for i in input_id]\n",
    "prediction = model.predict([[input_id], [segment_id], [mask_input]])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49339]], dtype=float32)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content = '檢察官其他人名依法判徐正憲貪污罪'\n",
    "input_id, segment_id = tokenizer.encode(content, max_len=maxlen)\n",
    "mask_input = [transfer(i) for i in input_id]\n",
    "prediction = model2.predict([[input_id], [segment_id], [mask_input]])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 建立 aml 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_tokenizer(dict_path):\n",
    "    \n",
    "    token_dict = {}\n",
    "    with codecs.open(dict_path, 'r', 'utf8') as reader:\n",
    "        for line in reader:\n",
    "            token = line.strip()\n",
    "            token_dict[token] = len(token_dict)\n",
    "            \n",
    "    return token_dict\n",
    "\n",
    "def transfer(i):\n",
    "    \n",
    "    if i != 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def encoded(tokenizer, data, maxlen):\n",
    "    \n",
    "    x, y, z = [], [], []\n",
    "    if 'content' in data.columns:\n",
    "        for content in data['content']:\n",
    "            x1, x2 = tokenizer.encode(content, max_len=maxlen)\n",
    "            x3 = [transfer(i) for i in x1]\n",
    "            x.append(x1)\n",
    "            y.append(x2)\n",
    "            z.append(x3)\n",
    "    elif 'Sentence' in data.columns:\n",
    "        for content in data['Sentence']:\n",
    "            x1, x2 = tokenizer.encode(content, max_len=maxlen)\n",
    "            x3 = [transfer(i) for i in x1]\n",
    "            x.append(x1)\n",
    "            y.append(x2)\n",
    "            z.append(x3)\n",
    "            \n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = create_tokenizer(dict_path)\n",
    "tokenizer = Tokenizer(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 256\n",
    "batch_size = 8\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.asarray(train['aml_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id, segment_id, mask_input = encoded(tokenizer, train, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bert_LSTM_model():\n",
    "    \n",
    "    model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True, seq_len=maxlen)\n",
    "    sequence_output = model.layers[-9].output\n",
    "    #sequence_output = Lambda(lambda x: x[:, 0])(sequence_output)\n",
    "    sequence_output = Bidirectional(LSTM(128, return_sequences=False))(sequence_output)\n",
    "    output = Dense(1, activation='sigmoid')(sequence_output)\n",
    "    model = Model(model.input, output)\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    model.layers[-1].trainable = True\n",
    "    model.layers[-2].trainable = True\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = bert_LSTM_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入模型\n",
    "model.load_weights('aml_model_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "\n",
    "optimizer = AdamWarmup(total_steps, warmup_steps, lr=1e-3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_acc', patience=1)\n",
    "                 #,ModelCheckpoint(filepath='AML_bert.h5', monitor='val_loss', save_best_only=True)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.fit([input_id, segment_id, mask_input],\n",
    "          label,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          #validation_split=0.1,\n",
    "          #callbacks=callback_list\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('aml_model_weight_512.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 建立 NER 模型\n",
    "### transfer_NER 要跑 1.5 小時，訓練模型要跑 17mins/epoch，所以load weight就好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把大於512的新聞以句點分段 (bert最多只能吃512)\n",
    "def split_content(data):\n",
    "    data_more_split = pd.DataFrame()\n",
    "    for i, row in data.iterrows():\n",
    "        if (len(row['content']) > 512) & (len(row['content']) <= 1024):\n",
    "\n",
    "            s = row['content']\n",
    "            s_split = [(i, abs(len(s)//2 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            idx_left = min(s_split, key=lambda x: x[1])[0]\n",
    "            first = \"。\".join([s_split[i][2] for i in range(idx_left)])\n",
    "            second = \"。\".join([s_split[i][2] for i in range(idx_left, len(s_split))])    \n",
    "            contents = [first, second]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content}, index=[66]), ignore_index=True)\n",
    "\n",
    "        elif len(row['content']) > 1024:\n",
    "\n",
    "            s = row['content']\n",
    "            s_split1 = [(i, abs(len(s)//3 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            s_split2 = [(i, abs(len(s)*2//3 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            idx_left1 = min(s_split1, key=lambda x: x[1])[0]\n",
    "            idx_left2 = min(s_split2, key=lambda x: x[1])[0]\n",
    "            first = \"。\".join([s_split1[i][2] for i in range(idx_left1)])\n",
    "            second = \"。\".join([s_split1[i][2] for i in range(idx_left1, idx_left2)])\n",
    "            third = \"。\".join([s_split1[i][2] for i in range(idx_left2, len(s_split1))])\n",
    "            contents = [first, second, third]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content}, index=[66]), ignore_index=True)\n",
    "    \n",
    "    return data_more_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_ner = 512\n",
    "batch_size = 8\n",
    "epochs = 3\n",
    "input_shape = (maxlen_ner, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得 NER input array (陳水扁貪汙 -> CKIP(陳水扁) -> 1 2 2 0 0)\n",
    "def transfer_NER(data, tokenizer, maxlen):\n",
    "    people_list = []\n",
    "    first_name = ['申', '龔', '馮', '昌', '劉', '習', '陽', '顧', '鍾', '胡', '許', '魏',    '傅', '季', '扶', '柳', '狄', '焦', '封', '李', '羿', '刁', '和', '邴',    '陸', '王', '杜', '能', '侯', '伍', '平', '竺', '樂', '繆', '欒', '湛',    '道', '花', '賴', '浦', '萬', '章', '宮', '勾', '邵', '印', '夏', '杭',    '溥', '左', '池', '公', '閻', '符', '奚', '臧', '羅', '空', '璩', '巴',    '酈', '范', '談', '金', '顏', '慎', '郭', '僪', '聞', '車', '闞', '相',    '童', '雙', '方', '莊', '容', '姚', '田', '薛', '閔', '翟', '簡',    '蔚', '茹', '淩', '戴', '余', '鞏', '房', '富', '牛', '饒', '計', '居',    '後', '舒', '席', '翁', '祝', '鬱', '訾', '隆', '匡', '弘', '曆', '範',    '越', '趙', '卻', '岑', '隗', '冷', '張', '山', '松', '柯', '嵇', '韓',    '蕭', '褚', '殳', '滕', '滿', '洪', '荀', '庾', '廖', '盧', '危', '竇',    '曾', '郎', '遊', '穀', '慕', '禹', '凌', '廉', '邢', '梁', '葉',    '郝', '終', '齊', '藺', '曹', '全', '高', '樊', '史', '桂', '廣', '段',    '江', '餘', '袁', '弓', '牧', '魚', '儲', '尚', '逄', '尹', '通', '懷',    '皮', '何', '倪', '包', '晁', '涂', '蓬', '屠', '巫', '須', '巢', '卞',    '楊', '成', '孟', '楚', '呂', '古', '毋', '伊', '賁', '喻', '糜',    '蔔', '艾', '藍', '龐', '諸', '別', '任', '管', '冀', '壽', '惠', '梅',    '孫', '從', '康', '常', '駱', '鞠', '沈', '黨', '沙', '鳳', '郁', '邊',    '仰', '溫', '路', '逮', '賀', '雷', '鈄', '明', '裴', '滑', '毛', '費',    '關', '時', '步', '麴', '裘', '蒲', '司', '查', '錢', '盛', '霍', '鮑',    '彭', '龍', '沃', '單', '勞', '秋', '祖', '殷', '茅', '敖', '郗', '石',    '鐘', '嚴', '畢', '燕', '姜', '經', '程', '厙', '柏', '汪', '婁', '胥',    '聶', '邰', '桑', '辛', '扈', '穆', '仲', '紅', '項', '師', '桓', '黃',    '堵', '貢', '詹', '朱', '蔡', '戈', '于', '甄', '束', '屈', '索', '晏',    '阮', '魯', '虞', '歐', '濮', '俞', '黎', '文', '應', '姬', '貝', '籍',    '莘', '戚', '鄭', '郜', '景', '宋', '宗', '昝', '卓', '蒯', '馬', '顔',    '蘇', '衛', '東', '瞿', '蒼', '莫', '邱', '潘', '家', '林', '芮', '麻',    '元', '武', '強', '鈕', '陳', '井', '於', '游', '耿', '柴', '荊', '韶',    '易', '宿', '施', '鹹', '秦', '班', '甯', '汲', '酆', '暴', '尤',    '祿', '苗', '權', '仇', '都', '羊', '榮', '陶', '支', '賈', '白', '葛',    '暨', '解', '靳', '伏', '唐', '華', '吉', '融', '豐', '安', '衡', '那',    '闕', '俄', '盍', '鄔', '蒙', '利', '鄂', '謝', '宓', '湯', '喬', '孔',    '養', '紀', '幹', '牟', '連', '宰', '蔣', '雍', '益', '寇', '祁', '熊',    '崔', '丁', '薊', '譚', '吳', '烏', '周', '農', '徐', '充', '向', '宦',    '董', '甘', '冉', '韋', '米', '鄒', '鄧', '戎', '水']\n",
    "    label = np.zeros([len(data), maxlen])\n",
    "    \n",
    "    # 用CKIP抓出每個新聞的名字\n",
    "    for index, (_, row) in enumerate(data.iterrows()):\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        \n",
    "        token = tokenizer.tokenize(row['content'][0:maxlen])\n",
    "\n",
    "        if len(token) > maxlen:\n",
    "            token = token[0:maxlen-1]\n",
    "            token.append('[SEP]')\n",
    "\n",
    "        y = np.zeros([maxlen])\n",
    "        content = ''.join(token)\n",
    "        \n",
    "        #CKIP\n",
    "        word_sentence_list = ws([content],\n",
    "                    sentence_segmentation=True,\n",
    "                    segment_delimiter_set={'?', '？', '!', '！', '。', ',', '，', ';', ':', '、'})\n",
    "        pos_sentence_list = pos(word_sentence_list)\n",
    "        entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "        \n",
    "        people = [people for people in list(entity_sentence_list[0]) if (people[2] == 'PERSON') & (people[1] < maxlen)]\n",
    "        people = [people for people in people if ((len(people[3]) < 5) & (people[3][0] in first_name)) | ((len(people[3]) >= 5) & ('#' not in people[3]))]\n",
    "        people.sort()\n",
    "        people_list.append(people)\n",
    "        \n",
    "        #轉換成input array\n",
    "        j = 0\n",
    "        for person in people: \n",
    "            for i, _ in enumerate(token):        \n",
    "                if token[i:i+len(person[3])] == list(person[3]):\n",
    "                    if len(person) == 1:\n",
    "                        y[i+j] = 1\n",
    "                        token = token[i+1:]\n",
    "                        j = i+j+1\n",
    "                        break\n",
    "\n",
    "                    y[i+j] = 1\n",
    "                    y[i+j+1:i+j+len(person[3])] = 2\n",
    "                    token = token[i+len(person[3]):]\n",
    "                    j = i+j+len(person[3])\n",
    "                    break\n",
    "        label[index, :] = y\n",
    "    \n",
    "    #用不到 people_list，只是檢查用\n",
    "    return people_list, label.reshape([label.shape[0], label.shape[1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分句\n",
    "test_ner = aml_highrisk.drop(['name'], axis=1)\n",
    "data_less = test_ner[test_ner['content'].str.len() <= 512]\n",
    "data_more = test_ner[test_ner['content'].str.len() > 512]\n",
    "data_more_split = split_content(data_more)\n",
    "test_ner = data_less.append(data_more_split).reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "people_list, label = transfer_NER(train_ner, tokenizer, maxlen=maxlen_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id, segment_id, mask_input = encoded(tokenizer, train_ner, maxlen=maxlen_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_BiLSTM_CRF_model():\n",
    "    \n",
    "    ner_model = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True, seq_len=maxlen_ner)\n",
    "    bert_output = ner_model.layers[-9].output\n",
    "    X = Lambda(lambda x: x[:, 0: input_shape[0]])(bert_output)\n",
    "    X = Bidirectional(LSTM(128, return_sequences=True))(X)\n",
    "    #X = TimeDistributed(Dense(len(y_token_dict), activation='relu'))(X)\n",
    "    output = CRF(3, sparse_target = True)(X)    \n",
    "    ner_model = Model(ner_model.input, output)\n",
    "    \n",
    "    for layer in ner_model.layers:\n",
    "        layer.trainable = False\n",
    "    ner_model.layers[-1].trainable = True\n",
    "    ner_model.layers[-2].trainable = True\n",
    "    \n",
    "    return ner_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ner_model = bert_BiLSTM_CRF_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_NER 要跑 1.5 小時，訓練模型要跑 17mins/epoch，所以load weight就好\n",
    "ner_model.load_weights('ner_model_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=data.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "\n",
    "optimizer = AdamWarmup(total_steps, warmup_steps, lr=1e-3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_crf_accuracy', patience=1)\n",
    "                 #,ModelCheckpoint(filepath='AML_bert.h5', monitor='val_loss', save_best_only=True)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ner_model.compile(optimizer=optimizer,\n",
    "                  loss=crf_loss,\n",
    "                  metrics=[crf_accuracy])\n",
    "\n",
    "ner_model.fit([input_id, segment_id, mask_input],\n",
    "          label,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['aml_label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen_sentences = 256\n",
    "batch_size = 8\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不用跑\n",
    "# 把大於512的新聞以句點分段 (bert最多只能吃512)\n",
    "def split_content_model2(data):\n",
    "    data_more_split = pd.DataFrame()\n",
    "    for i, row in data.iterrows():\n",
    "        if (len(row['content']) > 512) & (len(row['content']) <= 1024):\n",
    "\n",
    "            s = row['content']\n",
    "            s_split = [(i, abs(len(s)//2 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            idx_left = min(s_split, key=lambda x: x[1])[0]\n",
    "            first = \"。\".join([s_split[i][2] for i in range(idx_left)])\n",
    "            second = \"。\".join([s_split[i][2] for i in range(idx_left, len(s_split))])    \n",
    "            contents = [first, second]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content, 'aml_label':row['aml_label']}, index=[66]), ignore_index=True)\n",
    "\n",
    "        elif len(row['content']) > 1024:\n",
    "\n",
    "            s = row['content']\n",
    "            s_split1 = [(i, abs(len(s)//3 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            s_split2 = [(i, abs(len(s)*2//3 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            idx_left1 = min(s_split1, key=lambda x: x[1])[0]\n",
    "            idx_left2 = min(s_split2, key=lambda x: x[1])[0]\n",
    "            first = \"。\".join([s_split1[i][2] for i in range(idx_left1)])\n",
    "            second = \"。\".join([s_split1[i][2] for i in range(idx_left1, idx_left2)])\n",
    "            third = \"。\".join([s_split1[i][2] for i in range(idx_left2, len(s_split1))])\n",
    "            contents = [first, second, third]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content, 'aml_label':row['aml_label']}, index=[66]), ignore_index=True)\n",
    "    \n",
    "    return data_more_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences_model2(test, people_list, stick, tokenizer=tokenizer, maxlen=maxlen_sentences):\n",
    "    \n",
    "    AML = pd.DataFrame(columns=['news_id', 'Name', 'Sentence'])\n",
    "    aml_highrisk = np.asarray(test['content'])\n",
    "    news_ids = np.asarray(test['news_id'])\n",
    "    people_list = list(test['people_list'])\n",
    "\n",
    "    \n",
    "    for k, (news_id, y_news) in enumerate(zip(news_ids ,aml_highrisk)): \n",
    "        #用，。？切分句子\n",
    "        y_news = y_news.replace('。','=。')\n",
    "        y_news = y_news.replace('，','*，')\n",
    "        y_news = y_news.replace('？','+？')\n",
    "        \n",
    "        news = re.split('，|。|？', y_news)\n",
    "        \n",
    "        news = [news.replace('=','。') for news in news]\n",
    "        news = [news.replace('*','，') for news in news]\n",
    "        news = [news.replace('+','？') for news in news]\n",
    "#############################################################################################################\n",
    "        for i in range(len(people_list[k])):\n",
    "            # 找出人名存在的 news index\n",
    "            index = [index for index, _ in enumerate(news) if people_list[k][i] in _]                                \n",
    "            x = [people for people in people_list[k] if people_list[k][i] not in people]\n",
    "\n",
    "            name = [name for name in people_list[k] if name != people_list[k][i]]\n",
    "            name = [name for name in name if ((len(name)<3) & (name[0] != people_list[k][i][0])) | (len(name)>=3)]\n",
    "            name.sort(reverse=True)\n",
    "\n",
    "            #if name != []:\n",
    "            #    text = [re.sub('|'.join(name), '其他人名', news) for news in news]\n",
    "            #else:\n",
    "            #    text = news\n",
    "\n",
    "            for j in index:\n",
    "\n",
    "                mid = news[j]\n",
    "\n",
    "                if j == 0:\n",
    "                    if len(news) != 1:\n",
    "                        end = news[j+1]  \n",
    "\n",
    "                        if True in [people in news[j+1] for people in x]:\n",
    "                            sentences = mid\n",
    "                        else:\n",
    "                            sentences = mid + end\n",
    "                    elif len(news) == 1:\n",
    "                        sentences = mid\n",
    "\n",
    "                elif j+1 == len(news):\n",
    "                    start = news[j-1]\n",
    "\n",
    "                    if True in [people in news[j-1] for people in x]:\n",
    "                        sentences = mid\n",
    "                    else:\n",
    "                        sentences = start + mid\n",
    "\n",
    "                else:\n",
    "                    end = news[j+1]\n",
    "                    start = news[j-1]                    \n",
    "\n",
    "                    if '。' in start:\n",
    "                        start = ''\n",
    "                    elif '。' in mid:\n",
    "                        end = ''                 \n",
    "\n",
    "                    if (True not in [people in news[j-1] for people in x]) & (True not in [people in news[j+1] for people in x]):\n",
    "                        sentences = start + mid + end\n",
    "                    elif (True not in [people in news[j-1] for people in x]) & (True in [people in news[j+1] for people in x]):\n",
    "                        sentences = start + mid\n",
    "                    elif (True in [people in news[j-1] for people in x]) & (True not in [people in news[j+1] for people in x]):\n",
    "                        sentences = mid + end\n",
    "                    else:\n",
    "                        sentences = mid      \n",
    "\n",
    "                AML = AML.append(pd.DataFrame([[news_ids[k] ,people_list[k][i], sentences]], columns=AML.columns))\n",
    "                #break  \n",
    "                \n",
    "    #若 stick==True 則把多筆同姓名句子以逗點合併 (效果不好)\n",
    "    if stick:\n",
    "        AML = AML.groupby(['news_id', 'Name'])['Sentence'].apply('，'.join).reset_index()\n",
    "    \n",
    "    \n",
    "    # 把指向同一人的姓名改成一樣（陳男 -> 陳水扁），若指向多人則不改（陳男 -> 陳致中、陳水扁）\n",
    "    # 將預測不完整的名字回填（王音 -> 王音之）\n",
    "    name_list = []\n",
    "    for ids in AML['news_id'].unique():\n",
    "        full_name = [name for name in AML[(AML['news_id'] == ids)]['Name']]\n",
    "        full_3name = [name for name in AML[(AML['news_id'] == ids)]['Name'] if len(name) == 3]\n",
    "        \n",
    "        a = Counter([name[0] for name in full_3name])\n",
    "        keep = [k for k,v in a.items() if v == 1]\n",
    "        full_3name_filter = [name for name in full_3name if name[0] in keep]\n",
    "        name_dict = dict((name[0], name) for name in full_3name_filter)   # ex: {'陳' : '陳水扁'}\n",
    "\n",
    "        name_dict_2 = dict(zip([name[0:2] for name in full_3name], full_3name))  # ex: {'王音': '王音之'}\n",
    "        \n",
    "        for name in full_name:\n",
    "            if (name[0] in name_dict.keys()) & (len(name) == 1):\n",
    "                name_list.append(name_dict.get(name[0]))\n",
    "            elif (name[0] in name_dict.keys()) & (len(name) == 2) & (name[-1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                                  '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                                  '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                                  '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                                  '趁', '仔', '依', '氏', '父']):\n",
    "                name_list.append(name_dict.get(name[0]))\n",
    "            elif (name in name_dict_2.keys()) & (len(name) == 2):\n",
    "                name_list.append(name_dict_2.get(name))\n",
    "            else:\n",
    "                name_list.append(name)\n",
    "                \n",
    "    \n",
    "    # 排除重複資料、排除一字、兩字簡稱、兩字三字四字姓不在姓氏表中的人\n",
    "    AML['Name'] = name_list\n",
    "    AML = AML.drop_duplicates()\n",
    "    AML = AML[AML['Name'].apply(lambda x: (len(x) > 1) )]\n",
    "    AML = AML[~AML['Name'].apply(lambda x: (len(x) == 2) & (x[1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                     '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                     '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                     '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                     '趁', '仔', '依', '氏', '父']))]\n",
    "    \n",
    "    return AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得名字 (預測結果為onehot的狀態)\n",
    "def get_name(input_id, y_pred):\n",
    "    \n",
    "    label_list = []\n",
    "    word_dict = {v: k for k, v in token_dict.items()}\n",
    "    \n",
    "    for input_data, y in zip(input_id, y_pred):\n",
    "        people_index = ''.join([str(a) for a in list(y)])\n",
    "        j = 0\n",
    "        name_list = []\n",
    "        split_index = re.findall('[12]2*', people_index)\n",
    "        name = ''.join([word_dict.get(input_data[index]) for index, value in enumerate(y) if value != 0])\n",
    "        \n",
    "        # [UNK], [PAD]會被算成 5 個字元，避免轉換成文字的index因長度不同對不上，故用 1 個字元的其他符號替代\n",
    "        # 王春甡 -> 王春[UNK] -> 王春?\n",
    "        name = name.replace('[UNK]','?')\n",
    "        name = name.replace('[PAD]','!')\n",
    "        \n",
    "        for i in split_index:\n",
    "            name_list.append(name[0+j:len(i)+j])\n",
    "            j = len(i) + j\n",
    "            \n",
    "        name_list = [name for name in name_list]\n",
    "        label_list.append(list(set(name_list)))\n",
    "    \n",
    "    return label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 將超過 512 的句子以句點拆成多句分段預測\n",
    "train_ner = train.drop(['name'], axis=1)\n",
    "data_less = train_ner[train_ner['content'].str.len() <= 512]\n",
    "data_more = train_ner[train_ner['content'].str.len() > 512]\n",
    "data_more_split = split_content_model2(data_more)\n",
    "train_ner = data_less.append(data_more_split).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# 3. NER 預測人名\n",
    "input_id, segment_id, mask_input = encoded(tokenizer, train_ner, maxlen=maxlen_ner)\n",
    "prediction = ner_model.predict([input_id, segment_id, mask_input])\n",
    "y_pred = np.argmax(prediction, axis=-1)\n",
    "people_list = get_name(input_id, y_pred)\n",
    "\n",
    "\n",
    "# 4. 將拆開的句子組合回去\n",
    "train_ner['people_list'] = people_list\n",
    "content = train_ner[['news_id', 'content', 'aml_label']]\n",
    "content = content.groupby(['news_id', 'aml_label'])['content'].apply(lambda x : '。'.join(x)).reset_index()\n",
    "people = train_ner[['news_id', 'aml_label', 'people_list']]\n",
    "people = people.groupby(['news_id', 'aml_label'])['people_list'].agg(sum).reset_index()\n",
    "people['people_list'] = [list(set(people)) for people in people['people_list']]\n",
    "train_ner = pd.merge(content, people, on=['news_id', 'aml_label'], how='left')\n",
    "\n",
    "# 5. 將 [UNK], [PAD] 轉換回來 (王春? -> 王春甡)\n",
    "for _, row in train_ner.iterrows():\n",
    "    for i, name in enumerate(row['people_list']):\n",
    "        if ('?' in name) | ('!' in name):\n",
    "            reexp = name.replace('?', '.').replace('!', '.')\n",
    "            row['people_list'][i] = re.search(reexp, row['content']).group()\n",
    "            \n",
    "AML = predict_sentences_model2(train_ner, list(train_ner['people_list']), tokenizer=tokenizer, maxlen=maxlen_sentences, stick=False)\n",
    "\n",
    "AML = AML.groupby(['news_id', 'Name'])['Sentence'].apply('，'.join).reset_index()\n",
    "\n",
    "train_name = train.drop(['content'], axis=1)\n",
    "s = train_name.apply(lambda x: pd.Series(x['name']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'Name'\n",
    "train_name = train_name.drop('name', axis=1).join(s)\n",
    "\n",
    "aml_train = pd.merge(AML, train_name, on=['news_id', 'Name'], how='left')\n",
    "aml_train = aml_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>aml_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>王派宏</td>\n",
       "      <td>自稱房產幽默大師的王派宏，涉吸金捲款25億落跑！他自稱炒房專家，，被害的投資人懷疑，王派宏已...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>李威儀</td>\n",
       "      <td>以250萬元行賄時任內政部都市計畫委員會委員李威儀與其學生藍秀琪；經法院12年審理，，201...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>王桂霜</td>\n",
       "      <td>12年前爆發的花蓮縣壽豐鄉鯉魚潭風景區的「綠湖國際大飯店」開發弊案，業者王桂霜為讓計畫案順利...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>藍秀琪</td>\n",
       "      <td>以250萬元行賄時任內政部都市計畫委員會委員李威儀與其學生藍秀琪；經法院12年審理，，201...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>陳廷智</td>\n",
       "      <td>「台灣第一家」涉嫌將工業用碳酸鎂摻入椒鹽粉等產品中出售，創辦人陳廷智之子、總經理陳星佑被高等...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>4980</td>\n",
       "      <td>王光遠</td>\n",
       "      <td>曾被週刊爆料涉嫌假冒華固建設高層，並涉土地投資詐騙糾紛的前國防部政治作戰總隊總隊長王光遠將軍...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>4981</td>\n",
       "      <td>邱佳亮</td>\n",
       "      <td>桃園市議員邱佳亮被控貪污案，一審遭判12年6月，，依據二審台灣高等法院裁定書指出，邱佳亮聲請...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>4996</td>\n",
       "      <td>楊天生</td>\n",
       "      <td>郭是長億集團董事長楊天生的姪女婿，曾任台灣省警務處督察、台中縣霧峰警分局長，</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>4996</td>\n",
       "      <td>蔡茂寅</td>\n",
       "      <td>長生透過台大教授蔡茂寅申請仲裁，事後高鐵局仲裁案敗訴，</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>4996</td>\n",
       "      <td>郭政權</td>\n",
       "      <td>前立委郭政權被控涉入機場捷運BOT案仲裁弊案，，有人供認22億是仲裁案佣金，其中7000萬交...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1061 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      news_id Name                                           Sentence  \\\n",
       "0          18  王派宏  自稱房產幽默大師的王派宏，涉吸金捲款25億落跑！他自稱炒房專家，，被害的投資人懷疑，王派宏已...   \n",
       "1          38  李威儀  以250萬元行賄時任內政部都市計畫委員會委員李威儀與其學生藍秀琪；經法院12年審理，，201...   \n",
       "2          38  王桂霜  12年前爆發的花蓮縣壽豐鄉鯉魚潭風景區的「綠湖國際大飯店」開發弊案，業者王桂霜為讓計畫案順利...   \n",
       "3          38  藍秀琪  以250萬元行賄時任內政部都市計畫委員會委員李威儀與其學生藍秀琪；經法院12年審理，，201...   \n",
       "4          41  陳廷智  「台灣第一家」涉嫌將工業用碳酸鎂摻入椒鹽粉等產品中出售，創辦人陳廷智之子、總經理陳星佑被高等...   \n",
       "...       ...  ...                                                ...   \n",
       "1056     4980  王光遠  曾被週刊爆料涉嫌假冒華固建設高層，並涉土地投資詐騙糾紛的前國防部政治作戰總隊總隊長王光遠將軍...   \n",
       "1057     4981  邱佳亮  桃園市議員邱佳亮被控貪污案，一審遭判12年6月，，依據二審台灣高等法院裁定書指出，邱佳亮聲請...   \n",
       "1058     4996  楊天生             郭是長億集團董事長楊天生的姪女婿，曾任台灣省警務處督察、台中縣霧峰警分局長，   \n",
       "1059     4996  蔡茂寅                        長生透過台大教授蔡茂寅申請仲裁，事後高鐵局仲裁案敗訴，   \n",
       "1060     4996  郭政權  前立委郭政權被控涉入機場捷運BOT案仲裁弊案，，有人供認22億是仲裁案佣金，其中7000萬交...   \n",
       "\n",
       "      aml_label  \n",
       "0           1.0  \n",
       "1           1.0  \n",
       "2           1.0  \n",
       "3           1.0  \n",
       "4           0.0  \n",
       "...         ...  \n",
       "1056        0.0  \n",
       "1057        1.0  \n",
       "1058        0.0  \n",
       "1059        0.0  \n",
       "1060        1.0  \n",
       "\n",
       "[1061 rows x 4 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aml_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = aml_train[aml_train['Sentence'].str.contains('檢察官')]\n",
    "aml_train = aml_train.append(extra).append(extra).append(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.asarray(aml_train['aml_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id, segment_id, mask_input = encoded(tokenizer, aml_train, maxlen_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def bert_LSTM_model2():\n",
    "    \n",
    "    model2 = load_trained_model_from_checkpoint(config_path, checkpoint_path, training=True, seq_len=maxlen_sentences)\n",
    "    sequence_output = model2.layers[-9].output\n",
    "    #sequence_output = Lambda(lambda x: x[:, 0])(sequence_output)\n",
    "    sequence_output = Bidirectional(LSTM(128, return_sequences=False))(sequence_output)\n",
    "    output = Dense(1, activation='sigmoid')(sequence_output)\n",
    "    model2 = Model(model2.input, output)\n",
    "    \n",
    "    for layer in model2.layers:\n",
    "        layer.trainable = False\n",
    "    model2.layers[-1].trainable = True\n",
    "    model2.layers[-2].trainable = True\n",
    "    \n",
    "    return model2\n",
    "\n",
    "model2 = bert_LSTM_model2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_steps, warmup_steps = calc_train_steps(\n",
    "    num_example=train.shape[0],\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    warmup_proportion=0.1,\n",
    ")\n",
    "\n",
    "optimizer = AdamWarmup(total_steps, warmup_steps, lr=1e-3, min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "                 keras.callbacks.EarlyStopping(monitor='val_acc', patience=1)\n",
    "                 #,ModelCheckpoint(filepath='AML_bert.h5', monitor='val_loss', save_best_only=True)\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1370/1370 [==============================] - 66s 48ms/step - loss: 0.3625 - acc: 0.8431\n",
      "Epoch 2/2\n",
      "1370/1370 [==============================] - 64s 47ms/step - loss: 0.2788 - acc: 0.8825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x26423c3dd48>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['acc'])\n",
    "\n",
    "model2.fit([input_id, segment_id, mask_input],\n",
    "          label,\n",
    "          epochs=epochs,\n",
    "          batch_size=batch_size,\n",
    "          #validation_split=0.1,\n",
    "          #callbacks=callback_list\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save_weights('aml_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('192_aml_model_stick.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.load_weights('aml_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_aml(model, test, aml_threshold):\n",
    "    \n",
    "    #第一階段預測，大於aml_threshold者為疑似aml文章\n",
    "    input_id, segment_id, mask_input = encoded(tokenizer, test, maxlen=maxlen)\n",
    "    prediction = model.predict([input_id, segment_id, mask_input])\n",
    "    prediction[prediction >= aml_threshold] = 1\n",
    "    prediction[prediction < aml_threshold] = 0\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentences(test, people_list, stick, threshold, tokenizer=tokenizer, maxlen=maxlen_sentences):\n",
    "    \n",
    "    time = datetime.now()\n",
    "    \n",
    "#    AML = pd.DataFrame(columns=['news_id', 'Name', 'Sentence'])\n",
    "#    aml_highrisk = np.asarray(test['content'][test['prediction'] == 1])\n",
    "#    news_ids = np.asarray(test['news_id'][test['prediction'] == 1])\n",
    "#    people_list = list(test['people_list'][test['prediction'] == 1])\n",
    "    \n",
    "    AML = pd.DataFrame(columns=['news_id', 'Name', 'Sentence'])\n",
    "    aml_highrisk = np.asarray(test['content'])\n",
    "    news_ids = np.asarray(test['news_id'])\n",
    "    people_list = list(test['people_list'])\n",
    "    \n",
    "    for k, (news_id, y_news) in enumerate(zip(news_ids ,aml_highrisk)): \n",
    "        #用，。？切分句子\n",
    "        y_news = y_news.replace('。','=。')\n",
    "        y_news = y_news.replace('，','*，')\n",
    "        y_news = y_news.replace('？','+？')\n",
    "        \n",
    "        news = re.split('，|。|？', y_news)\n",
    "        \n",
    "        news = [news.replace('=','。') for news in news]\n",
    "        news = [news.replace('*','，') for news in news]\n",
    "        news = [news.replace('+','？') for news in news]\n",
    "#############################################################################################################\n",
    "        for i in range(len(people_list[k])):\n",
    "            # 找出人名存在的 news index\n",
    "            index = [index for index, _ in enumerate(news) if people_list[k][i] in _]                                \n",
    "            x = [people for people in people_list[k] if people_list[k][i] not in people]\n",
    "\n",
    "            name = [name for name in people_list[k] if name != people_list[k][i]]\n",
    "            name = [name for name in name if ((len(name)<3) & (name[0] != people_list[k][i][0])) | (len(name)>=3)]\n",
    "            name.sort(reverse=True)\n",
    "\n",
    "            #if name != []:\n",
    "            #    text = [re.sub('|'.join(name), '其他人名', news) for news in news]\n",
    "            #else:\n",
    "            #    text = news\n",
    "\n",
    "            for j in index:\n",
    "\n",
    "                mid = news[j]\n",
    "                \n",
    "                if name != []:\n",
    "                    mid = re.sub('|'.join(name), '其他人名', mid)\n",
    "\n",
    "                if j == 0:\n",
    "                    if len(news) != 1:\n",
    "                        end = news[j+1]  \n",
    "\n",
    "                        if True in [people in news[j+1] for people in x]:\n",
    "                            sentences = mid\n",
    "                        else:\n",
    "                            sentences = mid + end\n",
    "                    elif len(news) == 1:\n",
    "                        sentences = mid\n",
    "\n",
    "                elif j+1 == len(news):\n",
    "                    start = news[j-1]\n",
    "\n",
    "                    if True in [people in news[j-1] for people in x]:\n",
    "                        sentences = mid\n",
    "                    else:\n",
    "                        sentences = start + mid\n",
    "\n",
    "                else:\n",
    "                    end = news[j+1]\n",
    "                    start = news[j-1]                    \n",
    "\n",
    "                    if '。' in start:\n",
    "                        start = ''\n",
    "                    elif '。' in mid:\n",
    "                        end = ''                 \n",
    "\n",
    "                    if (True not in [people in news[j-1] for people in x]) & (True not in [people in news[j+1] for people in x]):\n",
    "                        sentences = start + mid + end\n",
    "                    elif (True not in [people in news[j-1] for people in x]) & (True in [people in news[j+1] for people in x]):\n",
    "                        sentences = start + mid\n",
    "                    elif (True in [people in news[j-1] for people in x]) & (True not in [people in news[j+1] for people in x]):\n",
    "                        sentences = mid + end\n",
    "                    else:\n",
    "                        sentences = mid      \n",
    "\n",
    "                AML = AML.append(pd.DataFrame([[news_ids[k] ,people_list[k][i], sentences]], columns=AML.columns))\n",
    "                #break  \n",
    "#############################################################################################################        \n",
    "                \n",
    "#        for i in range(len(people_list[k])):\n",
    "#            # 找出人名存在的 news index\n",
    "#            index = [index for index, _ in enumerate(news) if people_list[k][i] in _]                           \n",
    "#            \n",
    "#            ##3\n",
    "#            x = [people for people in people_list[k] if people_list[k][i] not in people]\n",
    "#            \n",
    "#            for j in index:\n",
    "#                \n",
    "#                name = [name for name in people_list[k] if name != people_list[k][i]]\n",
    "#                name = [name for name in name if (len(name)>=1) & (name[0] != people_list[k][i][0])]\n",
    "#                name.sort(reverse=True)\n",
    "#                new_news = re.sub('|'.join(name), '其他人名', news[j])\n",
    "#                \n",
    "#                if j == 0:\n",
    "#                    if len(news) != 1:\n",
    "#                        new_news2 = re.sub('|'.join(name), '其他人名', news[j+1])  \n",
    "#                        sentences = new_news + new_news2\n",
    "#                    elif len(news) == 1:\n",
    "#                        sentences = new_news\n",
    "#\n",
    "#                elif j+1 == len(news):\n",
    "#                    new_news3 = re.sub('|'.join(name), '其他人名', news[j-1]) \n",
    "#                    sentences = new_news3 + '，' + new_news\n",
    "#            \n",
    "#                else:\n",
    "#                    new_news2 = re.sub('|'.join(name), '其他人名', news[j+1]) \n",
    "#                    new_news3 = re.sub('|'.join(name), '其他人名', news[j-1])                    \n",
    "#\n",
    "#                    \n",
    "#                    if '。' in new_news3:\n",
    "#                        new_news3 = ''\n",
    "#                    elif '。' in new_news:\n",
    "#                        new_news2 = '' \n",
    "#                        \n",
    "#                    sentences = new_news3 + new_news + new_news2\n",
    "#                \n",
    "#                AML = AML.append(pd.DataFrame([[news_ids[k] ,people_list[k][i], sentences]], columns=AML.columns))\n",
    "#                break\n",
    "#############################################################################################################        \n",
    "        \n",
    "       \n",
    "#        for i in range(len(people_list[k])):\n",
    "#            #找出人名存在的news index\n",
    "#            index = [index for index, _ in enumerate(news) if people_list[k][i] in _]                        \n",
    "#                   \n",
    "#            #取前後一句\n",
    "#            for j in index:\n",
    "#                \n",
    "#                name = [name for name in people_list[k] if name != people_list[k][i]]\n",
    "#                name = [name for name in name if (len(name)>=1) & (name[0] != people_list[k][i][0])]\n",
    "#                name.sort(reverse=True)\n",
    "#                new_news1 = re.sub('|'.join(name), '其他人名', news[j])\n",
    "#                \n",
    "#                if j == 0:\n",
    "#                    new_news2 = re.sub('|'.join(name), '其他人名', news[j+1])\n",
    "#                    sentences = new_news1 + new_news2\n",
    "#                elif j+1 == len(news):\n",
    "#                    new_news0 = re.sub('|'.join(name), '其他人名', news[j-1])\n",
    "#                    sentences = new_news0 + new_news1\n",
    "#                else:\n",
    "#                    new_news0 = re.sub('|'.join(name), '其他人名', news[j-1])\n",
    "#                    new_news2 = re.sub('|'.join(name), '其他人名', news[j+1])\n",
    "#                    sentences = new_news0 + new_news1 + new_news2\n",
    "#                    \n",
    "#                AML = AML.append(pd.DataFrame([[news_ids[k] ,people_list[k][i], sentences]], columns=AML.columns))\n",
    "#                #break\n",
    "#############################################################################################################                \n",
    "                \n",
    "    print('1.提取句子', datetime.now() - time)\n",
    "    time = datetime.now()\n",
    "    \n",
    "    #若 stick==True 則把多筆同姓名句子以逗點合併 (效果不好)\n",
    "    if stick:\n",
    "        AML = AML.groupby(['news_id', 'Name'])['Sentence'].apply('，'.join).reset_index()\n",
    "\n",
    "    \n",
    "    # 把指向同一人的姓名改成一樣（陳男 -> 陳水扁），若指向多人則不改（陳男 -> 陳致中、陳水扁）\n",
    "    # 將預測不完整的名字回填（王音 -> 王音之）\n",
    "    name_list = []\n",
    "    for ids in AML['news_id'].unique():\n",
    "        full_name = [name for name in AML[(AML['news_id'] == ids)]['Name']]\n",
    "        full_3name = [name for name in AML[(AML['news_id'] == ids)]['Name'] if len(name) == 3]\n",
    "        \n",
    "        a = Counter([name[0] for name in full_3name])\n",
    "        keep = [k for k,v in a.items() if v == 1]\n",
    "        full_3name_filter = [name for name in full_3name if name[0] in keep]\n",
    "        name_dict = dict((name[0], name) for name in full_3name_filter)   # ex: {'陳' : '陳水扁'}\n",
    "\n",
    "        name_dict_2 = dict(zip([name[0:2] for name in full_3name], full_3name))  # ex: {'王音': '王音之'}\n",
    "        \n",
    "        for name in full_name:\n",
    "            if (name[0] in name_dict.keys()) & (len(name) == 1):\n",
    "                name_list.append(name_dict.get(name[0]))\n",
    "            elif (name[0] in name_dict.keys()) & (len(name) == 2) & (name[-1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                                  '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                                  '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                                  '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                                  '趁', '仔', '依', '氏', '父']):\n",
    "                name_list.append(name_dict.get(name[0]))\n",
    "            elif (name in name_dict_2.keys()) & (len(name) == 2):\n",
    "                name_list.append(name_dict_2.get(name))\n",
    "            else:\n",
    "                name_list.append(name)\n",
    "                \n",
    "    print('2.整理名字', datetime.now() - time)\n",
    "    time = datetime.now()\n",
    "    \n",
    "    # 排除重複資料、排除一字、兩字簡稱、兩字三字四字姓不在姓氏表中的人\n",
    "    AML['Name'] = name_list\n",
    "    AML = AML.drop_duplicates()\n",
    "    AML = AML[AML['Name'].apply(lambda x: (len(x) > 1) )]\n",
    "    AML = AML[~AML['Name'].apply(lambda x: (len(x) == 2) & (x[1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                     '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                     '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                     '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                     '趁', '仔', '依', '氏', '父']))]\n",
    "    \n",
    "    \n",
    "    print('3.刪除名字', datetime.now() - time)\n",
    "    time = datetime.now()\n",
    "    \n",
    "    # 第二階段 預測句子\n",
    "    input_id, segment_id, mask_input = encoded(tokenizer, AML, maxlen=maxlen)\n",
    "    prediction = model2.predict([input_id, segment_id, mask_input])\n",
    "    AML['prediction'] = prediction\n",
    "    \n",
    "    \n",
    "    # 同一人只要有一筆資料大於閥值（max），則預測為 aml 人物；若新聞中無人大於閥值，則為非 aml 新聞\n",
    "    AML['prediction'] = AML['prediction'].apply(lambda x: 0 if x < threshold else 1)\n",
    "    AML = AML.groupby(['news_id', 'Name'])['prediction'].max().reset_index()\n",
    "    AML = AML[AML['prediction'] == 1]\n",
    "    AML = AML.groupby(['news_id','prediction'])['Name'].apply(list).reset_index()\n",
    "    \n",
    "    print('4.預測名字', datetime.now() - time)\n",
    "    \n",
    "    return AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(a, b):\n",
    "    \n",
    "    if (len(a) != 0) & (len(b) != 0):\n",
    "        recall = float(len(set(a) & set(b)) / len(a))\n",
    "        pecision = float(len(set(a) & set(b)) / len(b))\n",
    "        score = 2 / (np.reciprocal(recall) + np.reciprocal(pecision))\n",
    "        return score\n",
    "    elif (len(a) == 0) & (len(b) == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 網格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1 [NER法]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把大於512的新聞以句點分段 (bert最多只能吃512)\n",
    "def split_content(data):\n",
    "    data_more_split = pd.DataFrame()\n",
    "    for i, row in data.iterrows():\n",
    "        if (len(row['content']) > 512) & (len(row['content']) <= 1024):\n",
    "\n",
    "            s = row['content']\n",
    "            s_split = [(i, abs(len(s)//2 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            idx_left = min(s_split, key=lambda x: x[1])[0]\n",
    "            first = \"。\".join([s_split[i][2] for i in range(idx_left)])\n",
    "            second = \"。\".join([s_split[i][2] for i in range(idx_left, len(s_split))])    \n",
    "            contents = [first, second]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content, 'aml_label':row['aml_label'], 'prediction':row['prediction']}, index=[66]), ignore_index=True)\n",
    "\n",
    "        elif len(row['content']) > 1024:\n",
    "\n",
    "            s = row['content']\n",
    "            s_split1 = [(i, abs(len(s)//3 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            s_split2 = [(i, abs(len(s)*2//3 - s.find(x)), x) for i, x in enumerate(s.split('。'))]\n",
    "            idx_left1 = min(s_split1, key=lambda x: x[1])[0]\n",
    "            idx_left2 = min(s_split2, key=lambda x: x[1])[0]\n",
    "            first = \"。\".join([s_split1[i][2] for i in range(idx_left1)])\n",
    "            second = \"。\".join([s_split1[i][2] for i in range(idx_left1, idx_left2)])\n",
    "            third = \"。\".join([s_split1[i][2] for i in range(idx_left2, len(s_split1))])\n",
    "            contents = [first, second, third]\n",
    "\n",
    "            for content in contents:\n",
    "                data_more_split = data_more_split.append(pd.DataFrame({'news_id':row['news_id'], 'content':content, 'aml_label':row['aml_label'], 'prediction':row['prediction']}, index=[66]), ignore_index=True)\n",
    "    \n",
    "    return data_more_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch_ner(df, model, test, aml_threshold, stick, threshold):\n",
    "    \n",
    "    time = datetime.now()\n",
    "    \n",
    "    # 1. 預測是否疑似 aml\n",
    "    prediction = predict_aml(model, test=test, aml_threshold=aml_threshold)\n",
    "    test['prediction'] = prediction\n",
    "    aml_highrisk = test[test['prediction'] == 1]\n",
    "    \n",
    "    # 2. 將超過 512 的句子以句點拆成多句分段預測\n",
    "    test_ner = aml_highrisk.drop(['name'], axis=1)\n",
    "    data_less = test_ner[test_ner['content'].str.len() <= 512]\n",
    "    data_more = test_ner[test_ner['content'].str.len() > 512]\n",
    "    data_more_split = split_content(data_more)\n",
    "    test_ner = data_less.append(data_more_split).reset_index().drop(['index'], axis=1)\n",
    "    \n",
    "    # 3. NER 預測人名\n",
    "    input_id, segment_id, mask_input = encoded(tokenizer, test_ner, maxlen=maxlen_ner)\n",
    "    prediction = ner_model.predict([input_id, segment_id, mask_input])\n",
    "    y_pred = np.argmax(prediction, axis=-1)\n",
    "    people_list = get_name(input_id, y_pred)\n",
    "    \n",
    "    \n",
    "    # 4. 將拆開的句子組合回去\n",
    "    test_ner['people_list'] = people_list\n",
    "    content = test_ner[['news_id', 'content', 'aml_label', 'prediction']]\n",
    "    content = content.groupby(['news_id', 'aml_label', 'prediction'])['content'].apply(lambda x : '。'.join(x)).reset_index()\n",
    "    people = test_ner[['news_id', 'aml_label', 'prediction', 'people_list']]\n",
    "    people = people.groupby(['news_id', 'aml_label', 'prediction'])['people_list'].agg(sum).reset_index()\n",
    "    people['people_list'] = [list(set(people)) for people in people['people_list']]\n",
    "    test_ner = pd.merge(content, people, on=['news_id', 'aml_label', 'prediction'], how='left')\n",
    "    \n",
    "    # 5. 將 [UNK], [PAD] 轉換回來 (王春? -> 王春甡)\n",
    "    for _, row in test_ner.iterrows():\n",
    "        for i, name in enumerate(row['people_list']):\n",
    "            if ('?' in name) | ('!' in name):\n",
    "                reexp = name.replace('?', '.').replace('!', '.')\n",
    "                row['people_list'][i] = re.search(reexp, row['content']).group()\n",
    "    \n",
    "    \n",
    "    print('0.CKIP', datetime.now() - time)\n",
    "    \n",
    "    # 6. 判斷名字前後句使是否為 aml\n",
    "    AML = predict_sentences(test_ner, list(test_ner['people_list']), tokenizer=tokenizer, maxlen=maxlen_sentences, stick=stick, threshold=threshold)\n",
    "    \n",
    "    test_prediction = pd.merge(test, AML[['news_id', 'Name']], on='news_id', how='left')\n",
    "    test_prediction['Name'] = test_prediction['Name'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    test_prediction['text_prediction'] = test_prediction['Name'].apply(lambda x: 0 if x == [] else 1)\n",
    "    test_prediction = test_prediction.drop(['content'],axis = 1)\n",
    "    test_prediction.columns = ['news_id', 'name', 'label', 'AML_prediction', 'Name_prediction', 'text_prediction']\n",
    "    \n",
    "    # 7. 算分數\n",
    "    score = []\n",
    "    for i in range(len(test_prediction)):\n",
    "        temp = f1_score(test_prediction['name'][i], test_prediction['Name_prediction'][i])\n",
    "        score.append(temp)\n",
    "        \n",
    "    test_prediction['f1_score'] = score    \n",
    "    total_score = sum(score)\n",
    "    aml_score = sum(test_prediction[test_prediction['label'] == 1]['f1_score'])    \n",
    "    \n",
    "    df = df.append(pd.DataFrame([[aml_threshold, threshold, stick, total_score, aml_score]], columns=df.columns))\n",
    "    \n",
    "    print('aml_threshold =', aml_threshold, 'stick =', stick, 'threshold =', threshold, 'total_score =', total_score, 'aml_score =', aml_score)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['aml_threshold', 'threshold', 'stick', 'total_score', 'aml_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test[test['aml_label'] ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocker\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.CKIP 0:00:05.628005\n",
      "1.提取句子 0:00:01.220765\n",
      "2.整理名字 0:00:00.048870\n",
      "3.刪除名字 0:00:00.003991\n",
      "4.預測名字 0:00:11.278925\n",
      "aml_threshold = 0.4 stick = False threshold = 0.3 total_score = 76.20158730158731 aml_score = 56.201587301587296\n",
      "0.CKIP 0:00:05.559844\n",
      "1.提取句子 0:00:01.221296\n",
      "2.整理名字 0:00:00.048871\n",
      "3.刪除名字 0:00:00.003988\n",
      "4.預測名字 0:00:09.574399\n",
      "aml_threshold = 0.4 stick = False threshold = 0.4 total_score = 77.11111111111111 aml_score = 57.11111111111109\n",
      "0.CKIP 0:00:05.558675\n",
      "1.提取句子 0:00:01.221761\n",
      "2.整理名字 0:00:00.048869\n",
      "3.刪除名字 0:00:00.002992\n",
      "4.預測名字 0:00:09.753418\n",
      "aml_threshold = 0.4 stick = False threshold = 0.5 total_score = 77.53333333333333 aml_score = 57.53333333333332\n",
      "0.CKIP 0:00:05.538762\n",
      "1.提取句子 0:00:01.222733\n",
      "2.整理名字 0:00:00.048870\n",
      "3.刪除名字 0:00:00.002994\n",
      "4.預測名字 0:00:09.682104\n",
      "aml_threshold = 0.4 stick = False threshold = 0.6 total_score = 75.85317460317461 aml_score = 55.8531746031746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocker\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for aml_threshold in [0.4]:\n",
    "    for threshold in [0.3, 0.4, 0.5, 0.6]:\n",
    "        for stick in [False]:        \n",
    "            df = GridSearch_ner(df, model, test, aml_threshold=aml_threshold, stick=stick, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocker\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.CKIP 0:00:05.766550\n",
      "1.提取句子 0:00:01.270661\n",
      "2.整理名字 0:00:00.048872\n",
      "3.刪除名字 0:00:00.003987\n",
      "4.預測名字 0:00:09.546463\n",
      "aml_threshold = 0.4 stick = False threshold = 0.3 total_score = 75.98650793650795 aml_score = 55.986507936507934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocker\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.CKIP 0:00:05.544135\n",
      "1.提取句子 0:00:01.225749\n",
      "2.整理名字 0:00:00.048872\n",
      "3.刪除名字 0:00:00.002994\n",
      "4.預測名字 0:00:09.644201\n",
      "aml_threshold = 0.4 stick = False threshold = 0.4 total_score = 75.39603174603175 aml_score = 55.396031746031746\n",
      "0.CKIP 0:00:05.556143\n",
      "1.提取句子 0:00:01.228686\n",
      "2.整理名字 0:00:00.048870\n",
      "3.刪除名字 0:00:00.004022\n",
      "4.預測名字 0:00:09.636243\n",
      "aml_threshold = 0.4 stick = False threshold = 0.5 total_score = 72.11984126984126 aml_score = 52.119841269841274\n",
      "0.CKIP 0:00:05.611538\n",
      "1.提取句子 0:00:01.231711\n",
      "2.整理名字 0:00:00.048870\n",
      "3.刪除名字 0:00:00.003989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b946f42fe833>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstick\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearch_ner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maml_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maml_threshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstick\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstick\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-ce070900916a>\u001b[0m in \u001b[0;36mGridSearch_ner\u001b[1;34m(df, model, test, aml_threshold, stick, threshold)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# 6. 判斷名字前後句使是否為 aml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mAML\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ner\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'people_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen_sentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstick\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstick\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mtest_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAML\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'news_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'news_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-7d3ee9840448>\u001b[0m in \u001b[0;36mpredict_sentences\u001b[1;34m(test, people_list, stick, threshold, tokenizer, maxlen)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;31m# 第二階段 預測句子\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[0minput_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAML\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msegment_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m     \u001b[0mAML\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3476\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for aml_threshold in [0.4]:\n",
    "    for threshold in [0.3, 0.4, 0.5, 0.6]:\n",
    "        for stick in [False]:        \n",
    "            df = GridSearch_ner(df, model, test, aml_threshold=aml_threshold, stick=stick, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocker\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.CKIP 0:00:05.520736\n",
      "1.提取句子 0:00:01.229748\n",
      "2.整理名字 0:00:00.048903\n",
      "3.刪除名字 0:00:00.003992\n",
      "4.預測名字 0:00:09.511551\n",
      "aml_threshold = 0.4 stick = False threshold = 0.3 total_score = 75.86825396825398 aml_score = 55.86825396825395\n"
     ]
    }
   ],
   "source": [
    "for aml_threshold in [0.4]:\n",
    "    for threshold in [0.3]:\n",
    "        for stick in [False]:        \n",
    "            df = GridSearch_ner(df, model, test, aml_threshold=aml_threshold, stick=stick, threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aml_threshold in [0.4]:\n",
    "    for threshold in [0.4]:\n",
    "        for stick in [False]:        \n",
    "            df = GridSearch_ner(df, model, test, aml_threshold=aml_threshold, stick=stick, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. NER, CKIP比較 (待整理)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocker\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# 預測是否疑似aml\n",
    "prediction = predict_aml(model, test, aml_threshold=0.4)\n",
    "test['prediction'] = prediction\n",
    "aml_highrisk = test[test['prediction'] == 1]\n",
    "\n",
    "# 將超過512的句子拆成多句分段預測\n",
    "test_ner = aml_highrisk.drop(['name'], axis=1)\n",
    "data_less = test_ner[test_ner['content'].str.len() <= 512]\n",
    "data_more = test_ner[test_ner['content'].str.len() > 512]\n",
    "data_more_split = split_content(data_more)\n",
    "test_ner = data_less.append(data_more_split).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# 預測人名\n",
    "input_id, segment_id, mask_input = encoded(tokenizer, test_ner, maxlen=maxlen_ner)\n",
    "prediction = ner_model.predict([input_id, segment_id, mask_input])\n",
    "y_pred = np.argmax(prediction, axis=-1)\n",
    "people_list = get_name(input_id, y_pred)\n",
    "\n",
    "# 將拆開的句子組合回去\n",
    "test_ner['people_list'] = people_list\n",
    "content = test_ner[['news_id', 'content', 'aml_label', 'prediction']]\n",
    "content = content.groupby(['news_id', 'aml_label', 'prediction'])['content'].apply(lambda x : '。'.join(x)).reset_index()\n",
    "people = test_ner[['news_id', 'aml_label', 'prediction', 'people_list']]\n",
    "people = people.groupby(['news_id', 'aml_label', 'prediction'])['people_list'].agg(sum).reset_index()\n",
    "people['people_list'] = [list(set(people)) for people in people['people_list']]\n",
    "test_ner = pd.merge(content, people, on=['news_id', 'aml_label', 'prediction'], how='left')\n",
    "\n",
    "# 將 [UNK], [PAD] 轉換回來\n",
    "for _, row in test_ner.iterrows():\n",
    "    for i, name in enumerate(row['people_list']):\n",
    "        if ('?' in name) | ('!' in name):\n",
    "            reexp = name.replace('?', '.').replace('!', '.')\n",
    "            row['people_list'][i] = re.search(reexp, row['content']).group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AML = pd.DataFrame(columns=['news_id', 'Name', 'Sentence'])\n",
    "aml_highrisk = np.asarray(test_ner['content'][test_ner['prediction'] == 1])\n",
    "news_ids = np.asarray(test_ner['news_id'][test_ner['prediction'] == 1])\n",
    "people_list = list(test_ner['people_list'][test_ner['prediction'] == 1])\n",
    "\n",
    "\n",
    "\n",
    "for k, (news_id, y_news) in enumerate(zip(news_ids ,aml_highrisk)): \n",
    "    #用，。？切分句子\n",
    "    y_news = y_news.replace('。','=。')\n",
    "    y_news = y_news.replace('，','*，')\n",
    "    y_news = y_news.replace('？','+？')\n",
    "\n",
    "    news = re.split('，|。|？', y_news)\n",
    "\n",
    "    news = [news.replace('=','。') for news in news]\n",
    "    news = [news.replace('*','，') for news in news]\n",
    "    news = [news.replace('+','？') for news in news]\n",
    "#############################################################################################################\n",
    "    for i in range(len(people_list[k])):\n",
    "        # 找出人名存在的 news index\n",
    "        index = [index for index, _ in enumerate(news) if people_list[k][i] in _]                                \n",
    "        x = [people for people in people_list[k] if people_list[k][i] not in people]\n",
    "\n",
    "        name = [name for name in people_list[k] if name != people_list[k][i]]\n",
    "        name = [name for name in name if ((len(name)<3) & (name[0] != people_list[k][i][0])) | (len(name)>=3)]\n",
    "        name.sort(reverse=True)\n",
    "\n",
    "        #if name != []:\n",
    "        #    text = [re.sub('|'.join(name), '其他人名', news) for news in news]\n",
    "        #else:\n",
    "        #    text = news\n",
    "\n",
    "        for j in index:\n",
    "\n",
    "            mid = news[j]\n",
    "\n",
    "            if j == 0:\n",
    "                if len(news) != 1:\n",
    "                    end = news[j+1]  \n",
    "\n",
    "                    if True in [people in news[j+1] for people in x]:\n",
    "                        sentences = mid\n",
    "                    else:\n",
    "                        sentences = mid + end\n",
    "                elif len(news) == 1:\n",
    "                    sentences = mid\n",
    "\n",
    "            elif j+1 == len(news):\n",
    "                start = news[j-1]\n",
    "\n",
    "                if True in [people in news[j-1] for people in x]:\n",
    "                    sentences = mid\n",
    "                else:\n",
    "                    sentences = start + mid\n",
    "\n",
    "            else:\n",
    "                end = news[j+1]\n",
    "                start = news[j-1]                    \n",
    "\n",
    "                if '。' in start:\n",
    "                    start = ''\n",
    "                elif '。' in mid:\n",
    "                    end = ''                 \n",
    "\n",
    "                if (True not in [people in news[j-1] for people in x]) & (True not in [people in news[j+1] for people in x]):\n",
    "                    sentences = start + mid + end\n",
    "                elif (True not in [people in news[j-1] for people in x]) & (True in [people in news[j+1] for people in x]):\n",
    "                    sentences = start + mid\n",
    "                elif (True in [people in news[j-1] for people in x]) & (True not in [people in news[j+1] for people in x]):\n",
    "                    sentences = mid + end\n",
    "                else:\n",
    "                    sentences = mid      \n",
    "\n",
    "            AML = AML.append(pd.DataFrame([[news_ids[k] ,people_list[k][i], sentences]], columns=AML.columns))\n",
    "            #break  \n",
    "#把指向同一人的姓名改成一樣（陳男 -> 陳水扁），若指向多人則不改（陳男 -> 陳致中、陳水扁）\n",
    "name_list = []\n",
    "for ids in AML['news_id'].unique():\n",
    "    full_name = [name for name in AML[(AML['news_id'] == ids)]['Name']]\n",
    "    full_3name = [name for name in AML[(AML['news_id'] == ids)]['Name'] if len(name) == 3]\n",
    "\n",
    "    a = Counter([name[0] for name in full_3name])\n",
    "    keep = [k for k,v in a.items() if v == 1]\n",
    "    full_3name_filter = [name for name in full_3name if name[0] in keep]\n",
    "    name_dict = dict((name[0], name) for name in full_3name_filter)   # '陳' : '陳水扁'\n",
    "\n",
    "    name_dict_2 = dict(zip([name[0:2] for name in full_3name], full_3name))  # '王音': '王音之'\n",
    "\n",
    "    for name in full_name:\n",
    "        if (name[0] in name_dict.keys()) & (len(name) == 1):\n",
    "            name_list.append(name_dict.get(name[0]))\n",
    "        elif (name[0] in name_dict.keys()) & (len(name) == 2) & (name[-1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                              '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                              '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                              '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                              '趁', '仔', '依', '氏', '父']):\n",
    "            name_list.append(name_dict.get(name[0]))\n",
    "        elif (name in name_dict_2.keys()) & (len(name) == 2):\n",
    "            name_list.append(name_dict_2.get(name))\n",
    "        else:\n",
    "            name_list.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#排除重複資料、排除一字、兩字簡稱、兩字三字四字姓不在姓氏表中的人\n",
    "AML['Name'] = name_list\n",
    "AML = AML.drop_duplicates()\n",
    "AML = AML[AML['Name'].apply(lambda x: (len(x) > 1) )]\n",
    "AML = AML[~AML['Name'].apply(lambda x: (len(x) == 2) & (x[1] in ['男', '嫌', '婦', '夫', '某', '女', '妻',\\\n",
    "                                                                 '員', '稱', '家', '哥', '媽', '生', '處',\\\n",
    "                                                                 '和', '揆', '要', '再', '董', '涉', '母',\\\n",
    "                                                                 '辱', '公', '少', '為', '指', '翁', '粉',\\\n",
    "                                                                 '趁', '仔', '依', '氏', '父']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_id, segment_id, mask_input = encoded(tokenizer, AML, maxlen=maxlen_sentences)\n",
    "prediction = model2.predict([input_id, segment_id, mask_input])\n",
    "AML['raw_prediction'] = np.round(prediction, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name_count = AML[['news_id', 'Name']].groupby(['news_id'])['Name'].value_counts()\n",
    "#name_count = name_count[name_count == 1].reset_index(name=\"count\").drop(['count'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 滿足mask條件的返回\n",
    "# AML['raw_prediction'] = AML['raw_prediction'].mask((AML['Name'].isin(name_count.Name)) & (AML['news_id'].isin(name_count.news_id)), AML['raw_prediction']/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rocker\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "AML['prediction'] = AML['raw_prediction'].apply(lambda x: 0 if x < 0.3 else 1)\n",
    "AML = AML.groupby(['news_id', 'Name'])['raw_prediction', 'prediction'].max().reset_index()\n",
    "AML = AML[AML['prediction'] == 1]\n",
    "AMLName = AML.groupby(['news_id','prediction'])['Name'].apply(list).reset_index()\n",
    "AMLPrediction = AML.groupby(['news_id'])['raw_prediction'].apply(list).apply(lambda x: np.round(x,2)).reset_index()\n",
    "AMLloss = pd.merge(AMLName, AMLPrediction, how='left', on = 'news_id')\n",
    "AML = pd.merge(test, AMLloss, how='left', on='news_id').drop(['content', 'prediction_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = pd.merge(test, AML[['news_id', 'Name']], on='news_id', how='left')\n",
    "test_prediction['Name'] = test_prediction['Name'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "test_prediction['text_prediction'] = test_prediction['Name'].apply(lambda x: 0 if x == [] else 1)\n",
    "test_prediction = test_prediction.drop(['content'],axis = 1)\n",
    "test_prediction.columns = ['news_id', 'name', 'label', 'AML_prediction', 'Name_prediction', 'text_prediction']\n",
    "\n",
    "aml = pd.merge(test[['news_id', 'content']], test_prediction, how='left', on='news_id')\n",
    "compare = pd.merge(aml, test_ner[['news_id', 'people_list']], on='news_id', how='left')\n",
    "compare['people_list'].name = 'ner_namelist'\n",
    "compare.to_csv('預測結果mytest.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>content</th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>AML_prediction</th>\n",
       "      <th>Name_prediction</th>\n",
       "      <th>text_prediction</th>\n",
       "      <th>people_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9999</td>\n",
       "      <td>為落實洗錢防制，有外商銀行「拒絕」立法委員等重要政治人物開戶。對此，金管會主委顧立雄昨表示，...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>瑞士調查局要求台灣外交部協助調查陳水扁家人黃睿靚，吳淑珍等人洗錢案情。早前陳水扁於8月14日...</td>\n",
       "      <td>[吳淑珍, 陳水扁, 陳致中, 黃睿靚]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳淑珍, 陳水扁, 陳致中, 黃睿靚]</td>\n",
       "      <td>1</td>\n",
       "      <td>[陳致中, 吳淑珍, 陳水扁, 洪秀柱, 黃睿靚]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>金管會今天上午公佈，常務副主委一職，由銀行局邱淑貞陞任，至於邱淑貞所遺銀行局局長，則由該局副...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>男子葉松茂誆稱行善，與台北市長郝龍斌等政治人物合照後，再拿照片詐騙民眾投資澳門威尼斯人賭場，...</td>\n",
       "      <td>[葉松茂, 葉明宗, 葉晉展]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[葉明宗, 葉晉展, 葉松茂, 郝龍斌]</td>\n",
       "      <td>1</td>\n",
       "      <td>[葉晉展, 葉明宗, 郝龍斌, 葉, 葉松茂, 葉某]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>有「情歌王子」之稱的台語歌手王建傑，投資髮廊，日前卻驚爆被髮廊負責人捲款逃逸，損失不少。據了...</td>\n",
       "      <td>[游登洲]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[游登洲, 王建傑]</td>\n",
       "      <td>1</td>\n",
       "      <td>[游登洲, 游, 江蕙, 王建傑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10004</td>\n",
       "      <td>債留台灣700億元、十大通緝犯之一的前東帝士總裁陳由豪，2年前因投資菲律賓11兆元聲名大噪。...</td>\n",
       "      <td>[陳由豪, 繆竹怡, 孫道存, 胡洪九]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[孫道存, 繆竹怡, 胡洪九, 陳由豪]</td>\n",
       "      <td>1</td>\n",
       "      <td>[胡洪九, 陳由豪, 杜特蒂, 繆竹怡, 陳, 孫道存, 繆]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10005</td>\n",
       "      <td>金管會今天下午舉行新、卸任主委交接典禮，由政務委員行政院羅秉成監交。新任主委黃天牧致詞時表示...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10006</td>\n",
       "      <td>網通品牌廠友訊今日召開股東會，全面改選董事，由市場派台鋼集團取得過半席次，拿下3席董事與3席...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10007</td>\n",
       "      <td>2007年力霸集團創辦人王又曾掏空力霸集團案爆發，案情喧騰一時，成為國內最大宗的經濟犯罪，掏...</td>\n",
       "      <td>[王又曾, 王金世英, 王令可, 王令麟]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[王令可, 王令甫, 王令興, 王令麟, 王又曾, 王金世英]</td>\n",
       "      <td>1</td>\n",
       "      <td>[王金世英, 王, 王又曾, 王令可, 王令麟, 王令甫, 王令興]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10008</td>\n",
       "      <td>政治人物求「斗內」，小額募款不僅可造成話題，更是人氣的重要指標，而最成功的莫過於民進黨201...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10009</td>\n",
       "      <td>涉嫌於內湖殺害3歲女童「小燈泡」的王景玉，一審、二審均依鑑定患思覺失調症，判無期徒刑。經高等...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10010</td>\n",
       "      <td>前總統馬英九涉洩密案，台北地院判無罪，高等法院改判刑4月，高院更一審今年7月判決無罪確定；據...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10011</td>\n",
       "      <td>老牌油脂大廠「福懋油」涉嫌內線交易及掏空案，在本報上周獨家披露內幕消息後，引起主管機關及檢調...</td>\n",
       "      <td>[吳美紅]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳星澄, 吳派, 吳美紅]</td>\n",
       "      <td>1</td>\n",
       "      <td>[吳星澄, 吳美紅, 吳派, 葉文籐, 許忠明]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10012</td>\n",
       "      <td>美麗華家族成員、德安集團董事長、鋼管大廠美亞(2020-TW)董事長黃春發，涉嫌掏空美亞，美...</td>\n",
       "      <td>[黃春發]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[黃春發]</td>\n",
       "      <td>1</td>\n",
       "      <td>[黃春發]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10013</td>\n",
       "      <td>台北101大樓前董事長、宏國集團副董事長林鴻明，被控利用不實土地交易掏空金尚昌公司，高等法院...</td>\n",
       "      <td>[林鴻明, 林南聰]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[林南聰, 林鴻明, 金尚昌]</td>\n",
       "      <td>1</td>\n",
       "      <td>[金, 林鴻明, 林, 金尚昌, 林南聰]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10014</td>\n",
       "      <td>幸福人壽前董事長鄧文聰涉掏空公司127億元，被判10年確定，目前在台北監獄執行中，日前他申請...</td>\n",
       "      <td>[鄧文聰]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[鄧文聰]</td>\n",
       "      <td>1</td>\n",
       "      <td>[鄧文聰]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10015</td>\n",
       "      <td>和旺聯合實業股份有限公司前董座劉永祥涉掏空公司資產50億，並挪用約5億元償還個人在澳門的賭債...</td>\n",
       "      <td>[劉永祥]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[劉永祥]</td>\n",
       "      <td>1</td>\n",
       "      <td>[劉永祥, 郭, 劉男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10016</td>\n",
       "      <td>創辦網拍「東京著衣」的鄭景太被控作假帳，以逾100張假發票來掏空公司。檢調今天約談鄭景太等1...</td>\n",
       "      <td>[鄭景太]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[侯靜雯, 周品均, 鄭景太]</td>\n",
       "      <td>1</td>\n",
       "      <td>[鄭景太, 侯靜雯, 李男, 周品均, 鄭, 李]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10017</td>\n",
       "      <td>新北市前副市長許志堅利用主導都更案於2015年向建商收受名錶、金條及現金共計615萬多元，最...</td>\n",
       "      <td>[許志堅, 周麗惠, 許士耘, 許志遠, 鄒雪娥]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[周麗惠, 許士耘, 許志堅, 許志遠, 鄒雪娥]</td>\n",
       "      <td>1</td>\n",
       "      <td>[鄒雪娥, 許志堅, 周麗惠, 周女, 許士耘, 許志遠]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10018</td>\n",
       "      <td>行政院副院長陳其邁可望在下周三日經民進黨中常會徵召後，投入高雄市長補選。不過陳其邁的高人氣，...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10019</td>\n",
       "      <td>全運會工程爆發貪污弊案，花蓮地檢署檢察官昨天指揮高雄市調處、法務部東部機動工作站，前往花蓮縣...</td>\n",
       "      <td>[李裕仁,  汪錦德]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李光濱, 李裕仁, 汪錦德]</td>\n",
       "      <td>1</td>\n",
       "      <td>[張, 汪錦德, 張逸華, 陳旭華, 徐榛蔚, 張志強, 邱, 侯, 李, 李光濱, 汪, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10020</td>\n",
       "      <td>花蓮縣議員蔡啟塔擔任花蓮市長期間，所涉違反貪污治罪條例案件，經臺灣高等法院臺中分院判處有期徒...</td>\n",
       "      <td>[蔡啟塔, 林正二]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[蔡啟塔]</td>\n",
       "      <td>1</td>\n",
       "      <td>[林正二, 蔡啟塔, 徐子芳]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10021</td>\n",
       "      <td>6月6日快訊傳來，罷韓同意票已破89萬3104票，比韓國瑜2018年11月當選高雄市長的89...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10022</td>\n",
       "      <td>花蓮縣議員王燕美被控涉嫌虛報助理薪資、謊報活動費用案，一審判有罪，應執行徒刑十二年，她不服，...</td>\n",
       "      <td>[王燕美, 張志豪]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[張志豪, 王燕美]</td>\n",
       "      <td>1</td>\n",
       "      <td>[王燕美, 王燕, 張志豪]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10023</td>\n",
       "      <td>不久前才爆發財務危機的國揚實業負責人侯西峰，經過調查局追查，發現可能有計畫的掏空公司資產，由...</td>\n",
       "      <td>[侯西峰]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[侯西峰, 侯西隆, 建剛, 王翔懋]</td>\n",
       "      <td>1</td>\n",
       "      <td>[侯西峰, 侯西風, 侯西隆, 建剛, 王翔懋]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10024</td>\n",
       "      <td>警政署今舉行警察節慶祝大會，總統蔡英文、行政院長蘇貞昌親自頒獎表揚今年獲選的28位全國模範警...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10025</td>\n",
       "      <td>經濟部長沈榮津今(27)日宣布，6月1日起國內生產之醫療口罩每日徵用量改為800萬片，其餘產...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10026</td>\n",
       "      <td>《CTWANT》今日以「趁機踹陳時中一腳　蘇貞昌拿自費醫材教訓衛福部」為題刊登＞指出，行政院...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10027</td>\n",
       "      <td>針對日前日本石垣市議會提案，預備將釣魚台更名成「登野城尖閣」，國民黨立委今(15)日抗議日本...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10028</td>\n",
       "      <td>金融史上首位檢察官轉任金管會副主委的許永欽26日表示，其多年的檢察官及兼任學校教書的經驗，整...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10029</td>\n",
       "      <td>在這波17位新任檢察首長中唯一由一審檢察長升任二審檢察長的邢泰釗，本著「誠惶誠恐，勤慎以赴」...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10030</td>\n",
       "      <td>為提升金融業對洗錢活動前置犯罪之偵測能力，發揮第一線防制措施效果，信託公會持續於2020年舉...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10031</td>\n",
       "      <td>嘉義地檢署偵辦台商吳承霖夫妻涉嫌地下匯兌124億案，19日起訴吳嫌等7人違反組織犯罪防制條例...</td>\n",
       "      <td>[吳承霖, 黃文鴻, 陳玟叡, 黃文鴻]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳承霖, 陳玟叡, 陳靜慧, 黃文鴻]</td>\n",
       "      <td>1</td>\n",
       "      <td>[王, 陳靜慧, 劉, 孫, 吳, 陳玟叡, 吳承霖, 彭, 黃文鴻]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10032</td>\n",
       "      <td>報載，日前所破獲名醫涉入的最大宗保險詐領案，情資的來源是保險犯罪防制中心的大數據分析，這個案...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10033</td>\n",
       "      <td>儘管tvbs公布民調說，一旦黃捷罷免案投票，估計只會有15%的罷免票，距離罷免成功需要的25...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10034</td>\n",
       "      <td>KPMG安侯建業聯合會計師事務所於今日舉辦「國際金融犯罪防制研討會」。KPMG安侯建業風險顧...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10035</td>\n",
       "      <td>因應全球區塊鏈熱潮，全球唯一「實名制區塊鏈」Maxonrow，融合金融、經濟、交通、娛樂及科...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10036</td>\n",
       "      <td>時任兆豐銀行新店分行女職員石蕙瑄。首次上稿05:43更新時間06:52時任兆豐銀行新店分行女...</td>\n",
       "      <td>[石蕙瑄, 許皓青]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[石蕙瑄, 許皓青]</td>\n",
       "      <td>1</td>\n",
       "      <td>[許男, 許皓青, 石女, 石蕙瑄, 石]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>10037</td>\n",
       "      <td>台北地檢署依詐欺、偽造文書等罪嫌起訴同藝劇團總監謝宗達。客家傳統戲曲演員謝宗達，童星時期還曾...</td>\n",
       "      <td>[謝宗達]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[謝宗達]</td>\n",
       "      <td>1</td>\n",
       "      <td>[葛, 謝男, 葛女, 羅時豐, 謝宗達]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10038</td>\n",
       "      <td>桃園「烤雞王」老闆陳星文，原本信用卡額度只有60萬元，卻涉嫌鑽花旗銀行信用卡系統的漏洞，在短...</td>\n",
       "      <td>[陳星文]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[陳星文]</td>\n",
       "      <td>1</td>\n",
       "      <td>[陳星文]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10039</td>\n",
       "      <td>「少龍」徐浩城涉以靈修之名詐財，另涉成立「仙女班」趁召\\r\\n見猥褻，還兼賣其加持過的小神明...</td>\n",
       "      <td>[徐浩城, 李美華]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐浩城, 李美華]</td>\n",
       "      <td>1</td>\n",
       "      <td>[徐浩城, 李女, 徐, 李美華]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10040</td>\n",
       "      <td>韓星宋讚養指控台籍經紀人李湘瑋騙他拍攝性愛影片，以及自慰、下體等照片，李事後被依強制、詐欺、...</td>\n",
       "      <td>[李湘瑋]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[宋讚養, 李湘瑋, 楊雅琇]</td>\n",
       "      <td>1</td>\n",
       "      <td>[宋讚養, 李湘瑋, 楊雅琇, 史蒂芬史匹柏, 李, 宋]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10041</td>\n",
       "      <td>檢警查出欣欣大眾公司董事長詹鴻圖的兒子詹竣宇是詐騙集團幹部，負責招攬台灣人赴越南當「叩客」，...</td>\n",
       "      <td>[詹竣宇]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[詹竣宇, 詹鴻圖]</td>\n",
       "      <td>1</td>\n",
       "      <td>[詹竣宇, 詹鴻圖]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10042</td>\n",
       "      <td>台灣瑞環公司前管理部長翁國瑞，利用保管公司印章之便，在4年2個月期間以螞蟻搬象的方式，陸續侵...</td>\n",
       "      <td>[翁國瑞]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[翁國瑞]</td>\n",
       "      <td>1</td>\n",
       "      <td>[環, 翁, 翁國瑞, 翁男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10043</td>\n",
       "      <td>檢調今兵分2路搜索，約談中華電信工程師蔡政峰等人到案。中華電信台北營運處工程師蔡政峰，疑因業...</td>\n",
       "      <td>[蔡政峰]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[蔡政峰]</td>\n",
       "      <td>1</td>\n",
       "      <td>[蔡男, 蔡政峰]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10044</td>\n",
       "      <td>王世均聲稱與周杰倫合夥開咖啡廳，誆投資人300萬元，被橋頭地院依詐欺罪判刑10個月。「驚世夫...</td>\n",
       "      <td>[王世均]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[周杰倫, 王世均]</td>\n",
       "      <td>1</td>\n",
       "      <td>[王世均, 王, 洪曉蕾, 謝, 周杰倫, 黃, 劉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10045</td>\n",
       "      <td>華南銀行神鬼理專張秀米挪用客戶存款11億餘元，今遭判刑。華南銀行理神鬼專張秀米被控涉嫌勾結外...</td>\n",
       "      <td>[張秀米]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[張秀米, 翁明鈞]</td>\n",
       "      <td>1</td>\n",
       "      <td>[翁明鈞, 翁男, 張秀米, 張女]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10046</td>\n",
       "      <td>台裔美籍商人沈伯錡，曾因被知名演員「豆豆先生」救過登上新聞版面，他前年遭美籍華裔富商陳照華指...</td>\n",
       "      <td>[沈伯錡]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[沈伯錡, 陳照華]</td>\n",
       "      <td>1</td>\n",
       "      <td>[王, 沈, 沈伯錡, 陳, 陳照華]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10047</td>\n",
       "      <td>中信金控前副董事長、中信慈善基金會董事長辜仲諒，纏訟13年的紅火案，更一審去年9月依違反金控...</td>\n",
       "      <td>[辜仲諒, 張明田, 陳俊哲]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[張明田, 葉建廷, 辜仲諒, 陳俊哲, 高俊雄]</td>\n",
       "      <td>1</td>\n",
       "      <td>[陳俊哲, 辜, 高俊雄, 辜仲諒, 張明田, 葉建廷]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>10048</td>\n",
       "      <td>台北地檢署昨指揮調查局新北市調查處，兵分15路搜索並約談許朝嘉等14人，今早依違反證券交易法...</td>\n",
       "      <td>[許朝嘉, 莊振添, 李仲凱, 李光利, 余郁慧, 余曉亭]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[余曉亭, 余郁慧, 李仲凱, 李光利, 莊振添, 許朝嘉]</td>\n",
       "      <td>1</td>\n",
       "      <td>[李光利, 余郁慧, 簡, 許朝嘉, 莊振添, 李仲凱, 余曉亭]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>10049</td>\n",
       "      <td>台南市前議員楊麗玉詐領助理費，遭判4年定讞。台南市前市議員楊麗玉，勾結2名助理詐領2010到...</td>\n",
       "      <td>[楊麗玉, 郭月娥, 陳銘鴻]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[楊麗玉, 郭月娥, 陳銘鴻]</td>\n",
       "      <td>1</td>\n",
       "      <td>[郭月娥, 楊, 陳銘鴻, 楊麗玉]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>10050</td>\n",
       "      <td>石姓女行員的前夫許皓青，被移送台北地檢署。首次上稿：15:41更新時間：19:30兆豐銀行新...</td>\n",
       "      <td>[許皓青, 石蕙瑄]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[石蕙瑄, 許皓青]</td>\n",
       "      <td>1</td>\n",
       "      <td>[許男, 周, 許皓青, 周女, 石女, 石蕙瑄, 石]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>10051</td>\n",
       "      <td>外交部前駐越南代表處一等秘書蕭裕文，被控圖利業者，利用核發簽證機會，放水當地留學仲介業者；高...</td>\n",
       "      <td>[蕭裕文]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[曹保麟, 蕭裕文]</td>\n",
       "      <td>1</td>\n",
       "      <td>[曹保麟, 蕭裕文, 蕭]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>10052</td>\n",
       "      <td>立委廖國棟特別助理塗裕盛涉嫌向石材暨資源產業研究發展中心施壓索取回扣，新北地檢署今日依詐欺取...</td>\n",
       "      <td>[塗裕盛, 林志善]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[塗裕盛, 廖國棟, 林志善]</td>\n",
       "      <td>1</td>\n",
       "      <td>[塗, 林志善, 塗男, 廖國棟, 塗裕盛]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>10053</td>\n",
       "      <td>超跑達人鄧超鴻，被控以「一車多賣」的方式坑富二代，遭士檢起訴。超跑車壇頗具知名度的「Beta...</td>\n",
       "      <td>[鄧超鴻]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[鄧超鴻]</td>\n",
       "      <td>1</td>\n",
       "      <td>[鄧超鴻, 鄧男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>10054</td>\n",
       "      <td>京倫集團董事長李俊琳、胡白玫夫婦，被新加坡李姓女富商指控，涉嫌擅自更改公司會議紀錄，將位於北...</td>\n",
       "      <td>[李俊琳, 胡白玫]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[侯佩岑, 劉真, 劉若英, 李俊琳, 胡白玫, 范瑋琪, 陳海茵]</td>\n",
       "      <td>1</td>\n",
       "      <td>[劉真, 李女, 劉若英, 李俊琳, 陳海茵, 范瑋琪, 侯佩岑, 胡白玫, 李]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>10055</td>\n",
       "      <td>前國家質檢總局副局長魏傳忠也因收賄12億多元人民幣，同樣被判處無期徒刑，終身剝奪政治權利，個...</td>\n",
       "      <td>[魏傳忠, 趙洪順]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[趙洪順, 魏傳忠]</td>\n",
       "      <td>1</td>\n",
       "      <td>[魏傳忠, 趙洪順]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>10056</td>\n",
       "      <td>前中國保監會主席項俊波涉貪，一審判刑11年。中國保險監督管理委員會前主席、原保監會黨委書記項...</td>\n",
       "      <td>[項俊波]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[俊波, 項俊波]</td>\n",
       "      <td>1</td>\n",
       "      <td>[項俊波, 俊波]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>10057</td>\n",
       "      <td>文化部前人文司長朱瑞皓，遭檢方聲請延押2月。台北地檢署偵辦台北市出版商業同業公會理事長盧欽政...</td>\n",
       "      <td>[朱瑞皓, 盧欽政, 周均亮, 陳慶華, 廖育強, 陳金源, 邱祥豪]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[周均亮, 廖育強, 朱瑞皓, 盧欽政, 邱祥豪, 陳慶華, 陳金源]</td>\n",
       "      <td>1</td>\n",
       "      <td>[廖男, 廖育強, 周, 陳慶華, 盧, 周均亮, 朱瑞皓, 陳金源, 邱祥豪, 盧欽政]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>10058</td>\n",
       "      <td>前北市議員許富男更一審判9年。前台北市議員許富男被控替特定瀝青廠商護航，圍標大台北地區的道路...</td>\n",
       "      <td>[許富男]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[許富男]</td>\n",
       "      <td>1</td>\n",
       "      <td>[許富男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10059</td>\n",
       "      <td>前中壢市民代表會副主席劉威德，6年前參選桃園改制直轄市後的第一屆市議員時，被控以水梨禮盒或每...</td>\n",
       "      <td>[劉威德, 劉興坊]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[劉威德]</td>\n",
       "      <td>1</td>\n",
       "      <td>[劉威德, 劉, 劉興坊]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>10060</td>\n",
       "      <td>宜蘭縣頭城鎮長曹乾舜因涉嫌收賄被起訴。宜蘭縣頭城鎮長曹乾舜2017年間辦理LED路燈採購案時...</td>\n",
       "      <td>[曹乾舜]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[曹乾舜]</td>\n",
       "      <td>1</td>\n",
       "      <td>[林, 曹男, 曹乾舜, 林女, 林男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>10061</td>\n",
       "      <td>監察院以10比0票數通過彈劾趙宏翰。台東縣大武鄉前鄉長趙宏翰，其任職鄉長、鄉公所秘書期間，涉...</td>\n",
       "      <td>[趙宏翰]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[王幼玲, 蔡崇義, 趙宏翰]</td>\n",
       "      <td>1</td>\n",
       "      <td>[王幼玲, 蔡崇義, 趙, 趙宏翰]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>10062</td>\n",
       "      <td>新北地方法院。新北市新莊區公所工務課技士林國憲、賴錦彰、林振謙，涉於2012年至2013年間...</td>\n",
       "      <td>[林國憲, 賴錦彰, 林振謙]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[林國憲, 林振謙, 賴錦彰]</td>\n",
       "      <td>1</td>\n",
       "      <td>[林振謙, 林, 林國憲, 賴錦彰]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>10063</td>\n",
       "      <td>國民黨籍宜蘭縣頭城鎮長曹乾舜辦理LED路燈採購案時，涉嫌收取業者三百萬元賄款，新北地檢署昨依...</td>\n",
       "      <td>[曹乾舜]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[曹乾舜]</td>\n",
       "      <td>1</td>\n",
       "      <td>[莊, 莊男, 曹, 曹乾舜, 邱, 李, 邱男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10064</td>\n",
       "      <td>前水利署水文技術組正工程司李榮崇涉嫌於2011年向得標廠商索賄60多萬元，檢調今依貪污治罪條...</td>\n",
       "      <td>[李榮崇]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李榮崇]</td>\n",
       "      <td>1</td>\n",
       "      <td>[李男, 李榮崇, 黃嘉妮]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10065</td>\n",
       "      <td>麟洛鄉2位前任鄉長蔡志和及李新煌，因涉嫌收受工程賄款被屏東地檢署查獲，依違反貪污治罪條例起訴...</td>\n",
       "      <td>[李新煌, 蔡志和]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李新煌, 蔡志和]</td>\n",
       "      <td>1</td>\n",
       "      <td>[蔡, 蔡志和, 李新煌, 黃, 李]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>10066</td>\n",
       "      <td>台北市監理所長袁國治涉收賄圖利，被法院收押禁見。首次上稿17:11更新時間18:49台北市區...</td>\n",
       "      <td>[袁國治]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[袁國治]</td>\n",
       "      <td>1</td>\n",
       "      <td>[袁男, 王, 盧, 陳男, 陳, 袁國治]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>10067</td>\n",
       "      <td>南投縣議員游宏達與南投縣府前工務處約僱人員黃海郕，透過白手套許忠嘉，以透露底標等方式協助特定...</td>\n",
       "      <td>[游宏達, 黃海郕, 許忠嘉]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[游宏達, 許忠嘉, 黃海郕]</td>\n",
       "      <td>1</td>\n",
       "      <td>[曾, 杜, 許忠嘉, 康, 楊, 廖, 劉, 黃海郕, 游宏達]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>10068</td>\n",
       "      <td>北市監理所長袁國治涉收賄圖利，遭收押禁見。台北市區監理所所長袁國治，涉嫌收受王姓停車場租賃業...</td>\n",
       "      <td>[袁國治]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[袁國治]</td>\n",
       "      <td>1</td>\n",
       "      <td>[袁男, 王, 袁, 袁國治, 黃, 李]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>10069</td>\n",
       "      <td>前新北市立聯合醫院院長沈希哲收受廠商10萬元賄賂，洩漏醫院採購標案底價。新北市立聯合醫院前院...</td>\n",
       "      <td>[沈希哲, 畢家俊, 朱仁武, 朱旋武]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[朱仁武, 朱旋武, 沈希哲, 畢家俊]</td>\n",
       "      <td>1</td>\n",
       "      <td>[朱, 沈, 林, 朱仁武, 沈希哲, 畢家俊, 朱旋武]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>10070</td>\n",
       "      <td>前雲林縣口湖鄉長蔡永常被依貪汙罪判刑七年半，今日再被撤職。男子蔡永常擔任雲林縣口湖鄉長期間，...</td>\n",
       "      <td>[蔡永常]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[蔡永常]</td>\n",
       "      <td>1</td>\n",
       "      <td>[林, 蔡永常, 林男]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>10071</td>\n",
       "      <td>航警局前二線三星警官孫一鳴涉嫌收受賄款，並在中國已婚女業務李委霖的色誘下綁標，購入七千餘萬元...</td>\n",
       "      <td>[孫一鳴, 蔡依仁, 李委霖]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[孫一鳴, 李委霖, 蔡依仁]</td>\n",
       "      <td>1</td>\n",
       "      <td>[李女, 李委霖, 蔡, 孫, 孫一鳴, 李, 蔡依仁]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>10072</td>\n",
       "      <td>新竹縣府環保局代理局長羅仕臣疑涉入廢水罰單的貪瀆案，經新竹地檢署複訊後被聲押。??新竹地檢署...</td>\n",
       "      <td>[羅仕臣]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[羅仕臣, 羅鈞盛]</td>\n",
       "      <td>1</td>\n",
       "      <td>[羅仕臣, 羅鈞盛, 周, 黃]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>10073</td>\n",
       "      <td>前北科大教授王文博棄保逃，被通緝到案。被產學界視為冷凍空調領域權威的前國立台北科技大學教授王...</td>\n",
       "      <td>[王文博, 陳錦賜, 郭斯傑]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[王文博, 郭斯傑, 陳錦賜]</td>\n",
       "      <td>1</td>\n",
       "      <td>[陳錦賜, 王文博, 王, 陳, 王男, 郭斯傑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>10074</td>\n",
       "      <td>高雄市殯葬管理處前課長胡燕鵬，向私營業者「玫瑰園墓園」收賄120萬元，指導業者出具假資料，以...</td>\n",
       "      <td>[胡燕鵬]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[胡燕鵬]</td>\n",
       "      <td>1</td>\n",
       "      <td>[胡男, 胡燕鵬]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>10075</td>\n",
       "      <td>民進黨籍屏東縣議員潘淑真本月十一日才被高雄高分院判決當選無效確定，解除縣議員職務，昨天屏東地...</td>\n",
       "      <td>[潘淑真]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[潘淑真]</td>\n",
       "      <td>1</td>\n",
       "      <td>[潘淑真, 陳]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>10076</td>\n",
       "      <td>新北市板橋清潔隊前隊長鍾茂松。新北市板橋清潔隊前隊長鍾茂松，被控賣官，涉收取10萬至50萬元...</td>\n",
       "      <td>[鍾茂松, 曾文堅]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[曾文堅, 江惠貞, 鍾茂松]</td>\n",
       "      <td>1</td>\n",
       "      <td>[鍾, 曾文堅, 鍾男, 鍾茂松, 謝, 高, 吳, 丁, 李, 江惠貞]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10077</td>\n",
       "      <td>前營建署署長、前桃園縣副縣長葉世文，涉及八德、林口A7合宜住宅收賄案及財產來源不明案，合併執...</td>\n",
       "      <td>[葉世文]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[葉世文]</td>\n",
       "      <td>1</td>\n",
       "      <td>[葉世文, 洪, 葉, 吳, 李]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>10078</td>\n",
       "      <td>桃園市議員陳榮基因賄選案，法院判當選無效確定。桃園市無黨籍山地原住民市議員陳榮基，因涉嫌賄選...</td>\n",
       "      <td>[陳榮基]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[蘇志強, 陳榮基]</td>\n",
       "      <td>1</td>\n",
       "      <td>[陳榮基, 蘇志強, 曾]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>10079</td>\n",
       "      <td>前省自來水公司董事長徐享崑因貪汙案被通緝，日前還陪中國經濟參訪團前往公館鄉農會參訪。前台灣省...</td>\n",
       "      <td>[徐享崑]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[徐享崑, 黃國昌]</td>\n",
       "      <td>1</td>\n",
       "      <td>[傅學鵬, 韓國瑜, 徐, 陳俊宗, 徐享崑, 黃國昌, 許滿顯, 李]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>10080</td>\n",
       "      <td>高市原民議員賴文德被起訴。獲高雄市長韓國瑜力挺當選的國民黨籍高市原住民市議員賴文德官司纏身，...</td>\n",
       "      <td>[賴文德]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[賴文德, 韓國瑜]</td>\n",
       "      <td>1</td>\n",
       "      <td>[賴文德, 韓國瑜]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10081</td>\n",
       "      <td>海南省官員楊思濤涉嫌受賄罪、濫用職權罪，18日遭檢方提起公訴，據中國官媒＞，非法收受賄賂金額...</td>\n",
       "      <td>[楊思濤]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[周永康, 張中生, 楊思濤]</td>\n",
       "      <td>1</td>\n",
       "      <td>[張中生, 楊思濤, 楊, 周永康]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>10082</td>\n",
       "      <td>被稱「最美慈善家」的「彩石珠寶」董事長蘇怡，涉嫌誆騙投資「彩鑽」，受害人數高達百餘人，詐騙金...</td>\n",
       "      <td>[蘇怡]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[李莊, 蘇怡]</td>\n",
       "      <td>1</td>\n",
       "      <td>[李莊, 蘇, 蘇怡]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>10083</td>\n",
       "      <td>網紅貴婦奈奈和丈夫黃博健所創立的醫美診所「杏立博全」，前年底傳出惡性倒閉。監委張武修調查，該...</td>\n",
       "      <td>[蘇陳端, 黃博健]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[黃博健]</td>\n",
       "      <td>1</td>\n",
       "      <td>[胡, 黃博健, 黃, 張武修, 黃立雄]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>10084</td>\n",
       "      <td>自稱龍巖南區副總吳祥志涉吸金破3億遭收押禁見；龍巖今聲明，吳祥志是承攬經銷商，並非龍巖公司的...</td>\n",
       "      <td>[吳祥志, 吳順益, 曾小樺]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[吳祥志, 吳順益, 曾小樺]</td>\n",
       "      <td>1</td>\n",
       "      <td>[吳男, 吳順益, 吳, 吳祥志, 曾小樺]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>10085</td>\n",
       "      <td>夏于喬的父親夏世紘涉嫌參與跨國投資公司富南斯吸金。曾找英國天后JessieJ、謝金燕、張惠妹...</td>\n",
       "      <td>[夏世紘]</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[夏世紘, 夏于喬, 張惠妹, 謝金燕]</td>\n",
       "      <td>1</td>\n",
       "      <td>[謝金燕, 任賢齊, 夏世紘, 蕭煌奇, 夏于喬, 張惠妹]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    news_id                                            content  \\\n",
       "0      9999  為落實洗錢防制，有外商銀行「拒絕」立法委員等重要政治人物開戶。對此，金管會主委顧立雄昨表示，...   \n",
       "1     10000  瑞士調查局要求台灣外交部協助調查陳水扁家人黃睿靚，吳淑珍等人洗錢案情。早前陳水扁於8月14日...   \n",
       "2     10001  金管會今天上午公佈，常務副主委一職，由銀行局邱淑貞陞任，至於邱淑貞所遺銀行局局長，則由該局副...   \n",
       "3     10002  男子葉松茂誆稱行善，與台北市長郝龍斌等政治人物合照後，再拿照片詐騙民眾投資澳門威尼斯人賭場，...   \n",
       "4     10003  有「情歌王子」之稱的台語歌手王建傑，投資髮廊，日前卻驚爆被髮廊負責人捲款逃逸，損失不少。據了...   \n",
       "5     10004  債留台灣700億元、十大通緝犯之一的前東帝士總裁陳由豪，2年前因投資菲律賓11兆元聲名大噪。...   \n",
       "6     10005  金管會今天下午舉行新、卸任主委交接典禮，由政務委員行政院羅秉成監交。新任主委黃天牧致詞時表示...   \n",
       "7     10006  網通品牌廠友訊今日召開股東會，全面改選董事，由市場派台鋼集團取得過半席次，拿下3席董事與3席...   \n",
       "8     10007  2007年力霸集團創辦人王又曾掏空力霸集團案爆發，案情喧騰一時，成為國內最大宗的經濟犯罪，掏...   \n",
       "9     10008  政治人物求「斗內」，小額募款不僅可造成話題，更是人氣的重要指標，而最成功的莫過於民進黨201...   \n",
       "10    10009  涉嫌於內湖殺害3歲女童「小燈泡」的王景玉，一審、二審均依鑑定患思覺失調症，判無期徒刑。經高等...   \n",
       "11    10010  前總統馬英九涉洩密案，台北地院判無罪，高等法院改判刑4月，高院更一審今年7月判決無罪確定；據...   \n",
       "12    10011  老牌油脂大廠「福懋油」涉嫌內線交易及掏空案，在本報上周獨家披露內幕消息後，引起主管機關及檢調...   \n",
       "13    10012  美麗華家族成員、德安集團董事長、鋼管大廠美亞(2020-TW)董事長黃春發，涉嫌掏空美亞，美...   \n",
       "14    10013  台北101大樓前董事長、宏國集團副董事長林鴻明，被控利用不實土地交易掏空金尚昌公司，高等法院...   \n",
       "15    10014  幸福人壽前董事長鄧文聰涉掏空公司127億元，被判10年確定，目前在台北監獄執行中，日前他申請...   \n",
       "16    10015  和旺聯合實業股份有限公司前董座劉永祥涉掏空公司資產50億，並挪用約5億元償還個人在澳門的賭債...   \n",
       "17    10016  創辦網拍「東京著衣」的鄭景太被控作假帳，以逾100張假發票來掏空公司。檢調今天約談鄭景太等1...   \n",
       "18    10017  新北市前副市長許志堅利用主導都更案於2015年向建商收受名錶、金條及現金共計615萬多元，最...   \n",
       "19    10018  行政院副院長陳其邁可望在下周三日經民進黨中常會徵召後，投入高雄市長補選。不過陳其邁的高人氣，...   \n",
       "20    10019  全運會工程爆發貪污弊案，花蓮地檢署檢察官昨天指揮高雄市調處、法務部東部機動工作站，前往花蓮縣...   \n",
       "21    10020  花蓮縣議員蔡啟塔擔任花蓮市長期間，所涉違反貪污治罪條例案件，經臺灣高等法院臺中分院判處有期徒...   \n",
       "22    10021  6月6日快訊傳來，罷韓同意票已破89萬3104票，比韓國瑜2018年11月當選高雄市長的89...   \n",
       "23    10022  花蓮縣議員王燕美被控涉嫌虛報助理薪資、謊報活動費用案，一審判有罪，應執行徒刑十二年，她不服，...   \n",
       "24    10023  不久前才爆發財務危機的國揚實業負責人侯西峰，經過調查局追查，發現可能有計畫的掏空公司資產，由...   \n",
       "25    10024  警政署今舉行警察節慶祝大會，總統蔡英文、行政院長蘇貞昌親自頒獎表揚今年獲選的28位全國模範警...   \n",
       "26    10025  經濟部長沈榮津今(27)日宣布，6月1日起國內生產之醫療口罩每日徵用量改為800萬片，其餘產...   \n",
       "27    10026  《CTWANT》今日以「趁機踹陳時中一腳　蘇貞昌拿自費醫材教訓衛福部」為題刊登＞指出，行政院...   \n",
       "28    10027  針對日前日本石垣市議會提案，預備將釣魚台更名成「登野城尖閣」，國民黨立委今(15)日抗議日本...   \n",
       "29    10028  金融史上首位檢察官轉任金管會副主委的許永欽26日表示，其多年的檢察官及兼任學校教書的經驗，整...   \n",
       "30    10029  在這波17位新任檢察首長中唯一由一審檢察長升任二審檢察長的邢泰釗，本著「誠惶誠恐，勤慎以赴」...   \n",
       "31    10030  為提升金融業對洗錢活動前置犯罪之偵測能力，發揮第一線防制措施效果，信託公會持續於2020年舉...   \n",
       "32    10031  嘉義地檢署偵辦台商吳承霖夫妻涉嫌地下匯兌124億案，19日起訴吳嫌等7人違反組織犯罪防制條例...   \n",
       "33    10032  報載，日前所破獲名醫涉入的最大宗保險詐領案，情資的來源是保險犯罪防制中心的大數據分析，這個案...   \n",
       "34    10033  儘管tvbs公布民調說，一旦黃捷罷免案投票，估計只會有15%的罷免票，距離罷免成功需要的25...   \n",
       "35    10034  KPMG安侯建業聯合會計師事務所於今日舉辦「國際金融犯罪防制研討會」。KPMG安侯建業風險顧...   \n",
       "36    10035  因應全球區塊鏈熱潮，全球唯一「實名制區塊鏈」Maxonrow，融合金融、經濟、交通、娛樂及科...   \n",
       "37    10036  時任兆豐銀行新店分行女職員石蕙瑄。首次上稿05:43更新時間06:52時任兆豐銀行新店分行女...   \n",
       "38    10037  台北地檢署依詐欺、偽造文書等罪嫌起訴同藝劇團總監謝宗達。客家傳統戲曲演員謝宗達，童星時期還曾...   \n",
       "39    10038  桃園「烤雞王」老闆陳星文，原本信用卡額度只有60萬元，卻涉嫌鑽花旗銀行信用卡系統的漏洞，在短...   \n",
       "40    10039  「少龍」徐浩城涉以靈修之名詐財，另涉成立「仙女班」趁召\\r\\n見猥褻，還兼賣其加持過的小神明...   \n",
       "41    10040  韓星宋讚養指控台籍經紀人李湘瑋騙他拍攝性愛影片，以及自慰、下體等照片，李事後被依強制、詐欺、...   \n",
       "42    10041  檢警查出欣欣大眾公司董事長詹鴻圖的兒子詹竣宇是詐騙集團幹部，負責招攬台灣人赴越南當「叩客」，...   \n",
       "43    10042  台灣瑞環公司前管理部長翁國瑞，利用保管公司印章之便，在4年2個月期間以螞蟻搬象的方式，陸續侵...   \n",
       "44    10043  檢調今兵分2路搜索，約談中華電信工程師蔡政峰等人到案。中華電信台北營運處工程師蔡政峰，疑因業...   \n",
       "45    10044  王世均聲稱與周杰倫合夥開咖啡廳，誆投資人300萬元，被橋頭地院依詐欺罪判刑10個月。「驚世夫...   \n",
       "46    10045  華南銀行神鬼理專張秀米挪用客戶存款11億餘元，今遭判刑。華南銀行理神鬼專張秀米被控涉嫌勾結外...   \n",
       "47    10046  台裔美籍商人沈伯錡，曾因被知名演員「豆豆先生」救過登上新聞版面，他前年遭美籍華裔富商陳照華指...   \n",
       "48    10047  中信金控前副董事長、中信慈善基金會董事長辜仲諒，纏訟13年的紅火案，更一審去年9月依違反金控...   \n",
       "49    10048  台北地檢署昨指揮調查局新北市調查處，兵分15路搜索並約談許朝嘉等14人，今早依違反證券交易法...   \n",
       "50    10049  台南市前議員楊麗玉詐領助理費，遭判4年定讞。台南市前市議員楊麗玉，勾結2名助理詐領2010到...   \n",
       "51    10050  石姓女行員的前夫許皓青，被移送台北地檢署。首次上稿：15:41更新時間：19:30兆豐銀行新...   \n",
       "52    10051  外交部前駐越南代表處一等秘書蕭裕文，被控圖利業者，利用核發簽證機會，放水當地留學仲介業者；高...   \n",
       "53    10052  立委廖國棟特別助理塗裕盛涉嫌向石材暨資源產業研究發展中心施壓索取回扣，新北地檢署今日依詐欺取...   \n",
       "54    10053  超跑達人鄧超鴻，被控以「一車多賣」的方式坑富二代，遭士檢起訴。超跑車壇頗具知名度的「Beta...   \n",
       "55    10054  京倫集團董事長李俊琳、胡白玫夫婦，被新加坡李姓女富商指控，涉嫌擅自更改公司會議紀錄，將位於北...   \n",
       "56    10055  前國家質檢總局副局長魏傳忠也因收賄12億多元人民幣，同樣被判處無期徒刑，終身剝奪政治權利，個...   \n",
       "57    10056  前中國保監會主席項俊波涉貪，一審判刑11年。中國保險監督管理委員會前主席、原保監會黨委書記項...   \n",
       "58    10057  文化部前人文司長朱瑞皓，遭檢方聲請延押2月。台北地檢署偵辦台北市出版商業同業公會理事長盧欽政...   \n",
       "59    10058  前北市議員許富男更一審判9年。前台北市議員許富男被控替特定瀝青廠商護航，圍標大台北地區的道路...   \n",
       "60    10059  前中壢市民代表會副主席劉威德，6年前參選桃園改制直轄市後的第一屆市議員時，被控以水梨禮盒或每...   \n",
       "61    10060  宜蘭縣頭城鎮長曹乾舜因涉嫌收賄被起訴。宜蘭縣頭城鎮長曹乾舜2017年間辦理LED路燈採購案時...   \n",
       "62    10061  監察院以10比0票數通過彈劾趙宏翰。台東縣大武鄉前鄉長趙宏翰，其任職鄉長、鄉公所秘書期間，涉...   \n",
       "63    10062  新北地方法院。新北市新莊區公所工務課技士林國憲、賴錦彰、林振謙，涉於2012年至2013年間...   \n",
       "64    10063  國民黨籍宜蘭縣頭城鎮長曹乾舜辦理LED路燈採購案時，涉嫌收取業者三百萬元賄款，新北地檢署昨依...   \n",
       "65    10064  前水利署水文技術組正工程司李榮崇涉嫌於2011年向得標廠商索賄60多萬元，檢調今依貪污治罪條...   \n",
       "66    10065  麟洛鄉2位前任鄉長蔡志和及李新煌，因涉嫌收受工程賄款被屏東地檢署查獲，依違反貪污治罪條例起訴...   \n",
       "67    10066  台北市監理所長袁國治涉收賄圖利，被法院收押禁見。首次上稿17:11更新時間18:49台北市區...   \n",
       "68    10067  南投縣議員游宏達與南投縣府前工務處約僱人員黃海郕，透過白手套許忠嘉，以透露底標等方式協助特定...   \n",
       "69    10068  北市監理所長袁國治涉收賄圖利，遭收押禁見。台北市區監理所所長袁國治，涉嫌收受王姓停車場租賃業...   \n",
       "70    10069  前新北市立聯合醫院院長沈希哲收受廠商10萬元賄賂，洩漏醫院採購標案底價。新北市立聯合醫院前院...   \n",
       "71    10070  前雲林縣口湖鄉長蔡永常被依貪汙罪判刑七年半，今日再被撤職。男子蔡永常擔任雲林縣口湖鄉長期間，...   \n",
       "72    10071  航警局前二線三星警官孫一鳴涉嫌收受賄款，並在中國已婚女業務李委霖的色誘下綁標，購入七千餘萬元...   \n",
       "73    10072  新竹縣府環保局代理局長羅仕臣疑涉入廢水罰單的貪瀆案，經新竹地檢署複訊後被聲押。??新竹地檢署...   \n",
       "74    10073  前北科大教授王文博棄保逃，被通緝到案。被產學界視為冷凍空調領域權威的前國立台北科技大學教授王...   \n",
       "75    10074  高雄市殯葬管理處前課長胡燕鵬，向私營業者「玫瑰園墓園」收賄120萬元，指導業者出具假資料，以...   \n",
       "76    10075  民進黨籍屏東縣議員潘淑真本月十一日才被高雄高分院判決當選無效確定，解除縣議員職務，昨天屏東地...   \n",
       "77    10076  新北市板橋清潔隊前隊長鍾茂松。新北市板橋清潔隊前隊長鍾茂松，被控賣官，涉收取10萬至50萬元...   \n",
       "78    10077  前營建署署長、前桃園縣副縣長葉世文，涉及八德、林口A7合宜住宅收賄案及財產來源不明案，合併執...   \n",
       "79    10078  桃園市議員陳榮基因賄選案，法院判當選無效確定。桃園市無黨籍山地原住民市議員陳榮基，因涉嫌賄選...   \n",
       "80    10079  前省自來水公司董事長徐享崑因貪汙案被通緝，日前還陪中國經濟參訪團前往公館鄉農會參訪。前台灣省...   \n",
       "81    10080  高市原民議員賴文德被起訴。獲高雄市長韓國瑜力挺當選的國民黨籍高市原住民市議員賴文德官司纏身，...   \n",
       "82    10081  海南省官員楊思濤涉嫌受賄罪、濫用職權罪，18日遭檢方提起公訴，據中國官媒＞，非法收受賄賂金額...   \n",
       "83    10082  被稱「最美慈善家」的「彩石珠寶」董事長蘇怡，涉嫌誆騙投資「彩鑽」，受害人數高達百餘人，詐騙金...   \n",
       "84    10083  網紅貴婦奈奈和丈夫黃博健所創立的醫美診所「杏立博全」，前年底傳出惡性倒閉。監委張武修調查，該...   \n",
       "85    10084  自稱龍巖南區副總吳祥志涉吸金破3億遭收押禁見；龍巖今聲明，吳祥志是承攬經銷商，並非龍巖公司的...   \n",
       "86    10085  夏于喬的父親夏世紘涉嫌參與跨國投資公司富南斯吸金。曾找英國天后JessieJ、謝金燕、張惠妹...   \n",
       "\n",
       "                                   name  label  AML_prediction  \\\n",
       "0                                    []      0             0.0   \n",
       "1                  [吳淑珍, 陳水扁, 陳致中, 黃睿靚]      1             1.0   \n",
       "2                                    []      0             0.0   \n",
       "3                       [葉松茂, 葉明宗, 葉晉展]      1             1.0   \n",
       "4                                 [游登洲]      1             1.0   \n",
       "5                  [陳由豪, 繆竹怡, 孫道存, 胡洪九]      1             1.0   \n",
       "6                                    []      0             0.0   \n",
       "7                                    []      0             0.0   \n",
       "8                 [王又曾, 王金世英, 王令可, 王令麟]      1             1.0   \n",
       "9                                    []      0             0.0   \n",
       "10                                   []      0             0.0   \n",
       "11                                   []      0             0.0   \n",
       "12                                [吳美紅]      1             1.0   \n",
       "13                                [黃春發]      1             1.0   \n",
       "14                           [林鴻明, 林南聰]      1             1.0   \n",
       "15                                [鄧文聰]      1             1.0   \n",
       "16                                [劉永祥]      1             1.0   \n",
       "17                                [鄭景太]      1             1.0   \n",
       "18            [許志堅, 周麗惠, 許士耘, 許志遠, 鄒雪娥]      1             1.0   \n",
       "19                                   []      0             0.0   \n",
       "20                          [李裕仁,  汪錦德]      1             1.0   \n",
       "21                           [蔡啟塔, 林正二]      1             1.0   \n",
       "22                                   []      0             0.0   \n",
       "23                           [王燕美, 張志豪]      1             1.0   \n",
       "24                                [侯西峰]      1             1.0   \n",
       "25                                   []      0             0.0   \n",
       "26                                   []      0             0.0   \n",
       "27                                   []      0             0.0   \n",
       "28                                   []      0             0.0   \n",
       "29                                   []      0             0.0   \n",
       "30                                   []      0             0.0   \n",
       "31                                   []      0             0.0   \n",
       "32                 [吳承霖, 黃文鴻, 陳玟叡, 黃文鴻]      1             1.0   \n",
       "33                                   []      0             0.0   \n",
       "34                                   []      0             0.0   \n",
       "35                                   []      0             0.0   \n",
       "36                                   []      0             0.0   \n",
       "37                           [石蕙瑄, 許皓青]      1             1.0   \n",
       "38                                [謝宗達]      1             1.0   \n",
       "39                                [陳星文]      1             1.0   \n",
       "40                           [徐浩城, 李美華]      1             1.0   \n",
       "41                                [李湘瑋]      1             1.0   \n",
       "42                                [詹竣宇]      1             1.0   \n",
       "43                                [翁國瑞]      1             1.0   \n",
       "44                                [蔡政峰]      1             1.0   \n",
       "45                                [王世均]      1             1.0   \n",
       "46                                [張秀米]      1             1.0   \n",
       "47                                [沈伯錡]      1             1.0   \n",
       "48                      [辜仲諒, 張明田, 陳俊哲]      1             1.0   \n",
       "49       [許朝嘉, 莊振添, 李仲凱, 李光利, 余郁慧, 余曉亭]      1             1.0   \n",
       "50                      [楊麗玉, 郭月娥, 陳銘鴻]      1             1.0   \n",
       "51                           [許皓青, 石蕙瑄]      1             1.0   \n",
       "52                                [蕭裕文]      1             1.0   \n",
       "53                           [塗裕盛, 林志善]      1             1.0   \n",
       "54                                [鄧超鴻]      1             1.0   \n",
       "55                           [李俊琳, 胡白玫]      1             1.0   \n",
       "56                           [魏傳忠, 趙洪順]      1             1.0   \n",
       "57                                [項俊波]      1             1.0   \n",
       "58  [朱瑞皓, 盧欽政, 周均亮, 陳慶華, 廖育強, 陳金源, 邱祥豪]      1             1.0   \n",
       "59                                [許富男]      1             1.0   \n",
       "60                           [劉威德, 劉興坊]      1             1.0   \n",
       "61                                [曹乾舜]      1             1.0   \n",
       "62                                [趙宏翰]      1             1.0   \n",
       "63                      [林國憲, 賴錦彰, 林振謙]      1             1.0   \n",
       "64                                [曹乾舜]      1             1.0   \n",
       "65                                [李榮崇]      1             1.0   \n",
       "66                           [李新煌, 蔡志和]      1             1.0   \n",
       "67                                [袁國治]      1             1.0   \n",
       "68                      [游宏達, 黃海郕, 許忠嘉]      1             1.0   \n",
       "69                                [袁國治]      1             1.0   \n",
       "70                 [沈希哲, 畢家俊, 朱仁武, 朱旋武]      1             1.0   \n",
       "71                                [蔡永常]      1             1.0   \n",
       "72                      [孫一鳴, 蔡依仁, 李委霖]      1             1.0   \n",
       "73                                [羅仕臣]      1             1.0   \n",
       "74                      [王文博, 陳錦賜, 郭斯傑]      1             1.0   \n",
       "75                                [胡燕鵬]      1             1.0   \n",
       "76                                [潘淑真]      1             1.0   \n",
       "77                           [鍾茂松, 曾文堅]      1             1.0   \n",
       "78                                [葉世文]      1             1.0   \n",
       "79                                [陳榮基]      1             1.0   \n",
       "80                                [徐享崑]      1             1.0   \n",
       "81                                [賴文德]      1             1.0   \n",
       "82                                [楊思濤]      1             1.0   \n",
       "83                                 [蘇怡]      1             1.0   \n",
       "84                           [蘇陳端, 黃博健]      1             1.0   \n",
       "85                      [吳祥志, 吳順益, 曾小樺]      1             1.0   \n",
       "86                                [夏世紘]      1             1.0   \n",
       "\n",
       "                        Name_prediction  text_prediction  \\\n",
       "0                                    []                0   \n",
       "1                  [吳淑珍, 陳水扁, 陳致中, 黃睿靚]                1   \n",
       "2                                    []                0   \n",
       "3                  [葉明宗, 葉晉展, 葉松茂, 郝龍斌]                1   \n",
       "4                            [游登洲, 王建傑]                1   \n",
       "5                  [孫道存, 繆竹怡, 胡洪九, 陳由豪]                1   \n",
       "6                                    []                0   \n",
       "7                                    []                0   \n",
       "8       [王令可, 王令甫, 王令興, 王令麟, 王又曾, 王金世英]                1   \n",
       "9                                    []                0   \n",
       "10                                   []                0   \n",
       "11                                   []                0   \n",
       "12                       [吳星澄, 吳派, 吳美紅]                1   \n",
       "13                                [黃春發]                1   \n",
       "14                      [林南聰, 林鴻明, 金尚昌]                1   \n",
       "15                                [鄧文聰]                1   \n",
       "16                                [劉永祥]                1   \n",
       "17                      [侯靜雯, 周品均, 鄭景太]                1   \n",
       "18            [周麗惠, 許士耘, 許志堅, 許志遠, 鄒雪娥]                1   \n",
       "19                                   []                0   \n",
       "20                      [李光濱, 李裕仁, 汪錦德]                1   \n",
       "21                                [蔡啟塔]                1   \n",
       "22                                   []                0   \n",
       "23                           [張志豪, 王燕美]                1   \n",
       "24                  [侯西峰, 侯西隆, 建剛, 王翔懋]                1   \n",
       "25                                   []                0   \n",
       "26                                   []                0   \n",
       "27                                   []                0   \n",
       "28                                   []                0   \n",
       "29                                   []                0   \n",
       "30                                   []                0   \n",
       "31                                   []                0   \n",
       "32                 [吳承霖, 陳玟叡, 陳靜慧, 黃文鴻]                1   \n",
       "33                                   []                0   \n",
       "34                                   []                0   \n",
       "35                                   []                0   \n",
       "36                                   []                0   \n",
       "37                           [石蕙瑄, 許皓青]                1   \n",
       "38                                [謝宗達]                1   \n",
       "39                                [陳星文]                1   \n",
       "40                           [徐浩城, 李美華]                1   \n",
       "41                      [宋讚養, 李湘瑋, 楊雅琇]                1   \n",
       "42                           [詹竣宇, 詹鴻圖]                1   \n",
       "43                                [翁國瑞]                1   \n",
       "44                                [蔡政峰]                1   \n",
       "45                           [周杰倫, 王世均]                1   \n",
       "46                           [張秀米, 翁明鈞]                1   \n",
       "47                           [沈伯錡, 陳照華]                1   \n",
       "48            [張明田, 葉建廷, 辜仲諒, 陳俊哲, 高俊雄]                1   \n",
       "49       [余曉亭, 余郁慧, 李仲凱, 李光利, 莊振添, 許朝嘉]                1   \n",
       "50                      [楊麗玉, 郭月娥, 陳銘鴻]                1   \n",
       "51                           [石蕙瑄, 許皓青]                1   \n",
       "52                           [曹保麟, 蕭裕文]                1   \n",
       "53                      [塗裕盛, 廖國棟, 林志善]                1   \n",
       "54                                [鄧超鴻]                1   \n",
       "55   [侯佩岑, 劉真, 劉若英, 李俊琳, 胡白玫, 范瑋琪, 陳海茵]                1   \n",
       "56                           [趙洪順, 魏傳忠]                1   \n",
       "57                            [俊波, 項俊波]                1   \n",
       "58  [周均亮, 廖育強, 朱瑞皓, 盧欽政, 邱祥豪, 陳慶華, 陳金源]                1   \n",
       "59                                [許富男]                1   \n",
       "60                                [劉威德]                1   \n",
       "61                                [曹乾舜]                1   \n",
       "62                      [王幼玲, 蔡崇義, 趙宏翰]                1   \n",
       "63                      [林國憲, 林振謙, 賴錦彰]                1   \n",
       "64                                [曹乾舜]                1   \n",
       "65                                [李榮崇]                1   \n",
       "66                           [李新煌, 蔡志和]                1   \n",
       "67                                [袁國治]                1   \n",
       "68                      [游宏達, 許忠嘉, 黃海郕]                1   \n",
       "69                                [袁國治]                1   \n",
       "70                 [朱仁武, 朱旋武, 沈希哲, 畢家俊]                1   \n",
       "71                                [蔡永常]                1   \n",
       "72                      [孫一鳴, 李委霖, 蔡依仁]                1   \n",
       "73                           [羅仕臣, 羅鈞盛]                1   \n",
       "74                      [王文博, 郭斯傑, 陳錦賜]                1   \n",
       "75                                [胡燕鵬]                1   \n",
       "76                                [潘淑真]                1   \n",
       "77                      [曾文堅, 江惠貞, 鍾茂松]                1   \n",
       "78                                [葉世文]                1   \n",
       "79                           [蘇志強, 陳榮基]                1   \n",
       "80                           [徐享崑, 黃國昌]                1   \n",
       "81                           [賴文德, 韓國瑜]                1   \n",
       "82                      [周永康, 張中生, 楊思濤]                1   \n",
       "83                             [李莊, 蘇怡]                1   \n",
       "84                                [黃博健]                1   \n",
       "85                      [吳祥志, 吳順益, 曾小樺]                1   \n",
       "86                 [夏世紘, 夏于喬, 張惠妹, 謝金燕]                1   \n",
       "\n",
       "                                          people_list  \n",
       "0                                                 NaN  \n",
       "1                           [陳致中, 吳淑珍, 陳水扁, 洪秀柱, 黃睿靚]  \n",
       "2                                                 NaN  \n",
       "3                         [葉晉展, 葉明宗, 郝龍斌, 葉, 葉松茂, 葉某]  \n",
       "4                                   [游登洲, 游, 江蕙, 王建傑]  \n",
       "5                     [胡洪九, 陳由豪, 杜特蒂, 繆竹怡, 陳, 孫道存, 繆]  \n",
       "6                                                 NaN  \n",
       "7                                                 NaN  \n",
       "8                  [王金世英, 王, 王又曾, 王令可, 王令麟, 王令甫, 王令興]  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                           [吳星澄, 吳美紅, 吳派, 葉文籐, 許忠明]  \n",
       "13                                              [黃春發]  \n",
       "14                              [金, 林鴻明, 林, 金尚昌, 林南聰]  \n",
       "15                                              [鄧文聰]  \n",
       "16                                       [劉永祥, 郭, 劉男]  \n",
       "17                          [鄭景太, 侯靜雯, 李男, 周品均, 鄭, 李]  \n",
       "18                      [鄒雪娥, 許志堅, 周麗惠, 周女, 許士耘, 許志遠]  \n",
       "19                                                NaN  \n",
       "20  [張, 汪錦德, 張逸華, 陳旭華, 徐榛蔚, 張志強, 邱, 侯, 李, 李光濱, 汪, ...  \n",
       "21                                    [林正二, 蔡啟塔, 徐子芳]  \n",
       "22                                                NaN  \n",
       "23                                     [王燕美, 王燕, 張志豪]  \n",
       "24                           [侯西峰, 侯西風, 侯西隆, 建剛, 王翔懋]  \n",
       "25                                                NaN  \n",
       "26                                                NaN  \n",
       "27                                                NaN  \n",
       "28                                                NaN  \n",
       "29                                                NaN  \n",
       "30                                                NaN  \n",
       "31                                                NaN  \n",
       "32                [王, 陳靜慧, 劉, 孫, 吳, 陳玟叡, 吳承霖, 彭, 黃文鴻]  \n",
       "33                                                NaN  \n",
       "34                                                NaN  \n",
       "35                                                NaN  \n",
       "36                                                NaN  \n",
       "37                              [許男, 許皓青, 石女, 石蕙瑄, 石]  \n",
       "38                              [葛, 謝男, 葛女, 羅時豐, 謝宗達]  \n",
       "39                                              [陳星文]  \n",
       "40                                  [徐浩城, 李女, 徐, 李美華]  \n",
       "41                      [宋讚養, 李湘瑋, 楊雅琇, 史蒂芬史匹柏, 李, 宋]  \n",
       "42                                         [詹竣宇, 詹鴻圖]  \n",
       "43                                    [環, 翁, 翁國瑞, 翁男]  \n",
       "44                                          [蔡男, 蔡政峰]  \n",
       "45                        [王世均, 王, 洪曉蕾, 謝, 周杰倫, 黃, 劉]  \n",
       "46                                 [翁明鈞, 翁男, 張秀米, 張女]  \n",
       "47                                [王, 沈, 沈伯錡, 陳, 陳照華]  \n",
       "48                       [陳俊哲, 辜, 高俊雄, 辜仲諒, 張明田, 葉建廷]  \n",
       "49                  [李光利, 余郁慧, 簡, 許朝嘉, 莊振添, 李仲凱, 余曉亭]  \n",
       "50                                 [郭月娥, 楊, 陳銘鴻, 楊麗玉]  \n",
       "51                       [許男, 周, 許皓青, 周女, 石女, 石蕙瑄, 石]  \n",
       "52                                      [曹保麟, 蕭裕文, 蕭]  \n",
       "53                             [塗, 林志善, 塗男, 廖國棟, 塗裕盛]  \n",
       "54                                          [鄧超鴻, 鄧男]  \n",
       "55          [劉真, 李女, 劉若英, 李俊琳, 陳海茵, 范瑋琪, 侯佩岑, 胡白玫, 李]  \n",
       "56                                         [魏傳忠, 趙洪順]  \n",
       "57                                          [項俊波, 俊波]  \n",
       "58      [廖男, 廖育強, 周, 陳慶華, 盧, 周均亮, 朱瑞皓, 陳金源, 邱祥豪, 盧欽政]  \n",
       "59                                              [許富男]  \n",
       "60                                      [劉威德, 劉, 劉興坊]  \n",
       "61                               [林, 曹男, 曹乾舜, 林女, 林男]  \n",
       "62                                 [王幼玲, 蔡崇義, 趙, 趙宏翰]  \n",
       "63                                 [林振謙, 林, 林國憲, 賴錦彰]  \n",
       "64                          [莊, 莊男, 曹, 曹乾舜, 邱, 李, 邱男]  \n",
       "65                                     [李男, 李榮崇, 黃嘉妮]  \n",
       "66                                [蔡, 蔡志和, 李新煌, 黃, 李]  \n",
       "67                             [袁男, 王, 盧, 陳男, 陳, 袁國治]  \n",
       "68                  [曾, 杜, 許忠嘉, 康, 楊, 廖, 劉, 黃海郕, 游宏達]  \n",
       "69                              [袁男, 王, 袁, 袁國治, 黃, 李]  \n",
       "70                      [朱, 沈, 林, 朱仁武, 沈希哲, 畢家俊, 朱旋武]  \n",
       "71                                       [林, 蔡永常, 林男]  \n",
       "72                       [李女, 李委霖, 蔡, 孫, 孫一鳴, 李, 蔡依仁]  \n",
       "73                                   [羅仕臣, 羅鈞盛, 周, 黃]  \n",
       "74                          [陳錦賜, 王文博, 王, 陳, 王男, 郭斯傑]  \n",
       "75                                          [胡男, 胡燕鵬]  \n",
       "76                                           [潘淑真, 陳]  \n",
       "77              [鍾, 曾文堅, 鍾男, 鍾茂松, 謝, 高, 吳, 丁, 李, 江惠貞]  \n",
       "78                                  [葉世文, 洪, 葉, 吳, 李]  \n",
       "79                                      [陳榮基, 蘇志強, 曾]  \n",
       "80               [傅學鵬, 韓國瑜, 徐, 陳俊宗, 徐享崑, 黃國昌, 許滿顯, 李]  \n",
       "81                                         [賴文德, 韓國瑜]  \n",
       "82                                 [張中生, 楊思濤, 楊, 周永康]  \n",
       "83                                        [李莊, 蘇, 蘇怡]  \n",
       "84                              [胡, 黃博健, 黃, 張武修, 黃立雄]  \n",
       "85                             [吳男, 吳順益, 吳, 吳祥志, 曾小樺]  \n",
       "86                     [謝金燕, 任賢齊, 夏世紘, 蕭煌奇, 夏于喬, 張惠妹]  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare[(compare['text_prediction'] == 1) & (compare['AML_prediction'] == 1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare[compare['label'] != compare['AML_prediction'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(compare[(compare['label'] == 0) & (compare['AML_prediction'] == 0) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare.to_csv('預測結果_ver_da.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare[compare['news_id']==10024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
